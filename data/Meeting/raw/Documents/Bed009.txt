professor f: So the what w we h have been doing i they would like us all to read these digits . grad b: OK and the way you do it is you just read the numbers not as  each single , so just like I do it . So we 're gonna try to finish by five so people who want to can go hear Nancy Chang 's talk ,  downstairs . professor f: And you guys are g giving talks on tomorrow and Wednesday lunch times , phd a: Yes . OK so , do y do you know what we 're gonna do ? grad b: I thought two things  we 'll introduce ourselves and what we do . And  we already talked with Andreas , Thilo and David and some lines of code were already written today and almost tested and just gonna say we have  again the recognizer to parser thing where we 're working on and that should be no problem and then that can be sort of developed  as needed when we get enter the tourism domain . phd a: S grad b: and  There one of our diligent workers has to sort of volunteer to look over Tilman 's shoulder while he is changing the grammars to English phd a:   Either we do a syllable concatenating  grammar for the English generation which is sort of starting from scratch and doing it the easy way , or we simply adopt the ah  more in - depth  style that is implemented in the German system and  are then able not only to produce strings but also the syntactic parse  not parse not the syntactic tree that is underneath in the syntactic structure which is the way we decided we were gonna go because A , it 's easier in the beginning phd a:   grad b: and  it does require some some knowledge of of those grammars and and and some ling linguistic background . Johno , are you gonna have some time t to do that  w with these guys ? grad e: Sure . And an Yeah , so I I actually wanna f to find out about it too , but I may not have time to get in . grad b: the the ultimate goal is that before they leave we we can run through the entire system input through output on at least one or two sample things . And  and by virtue of doing that then in this case Johno will have acquired the knowledge of how to extend it . grad b: And  also  Ralf has hooked up with David and you 're gonna continue either all through tonight or tomorrow on whatever to get the er parser interface working . grad b: They are thinning out and thickening out lattices and doing this kind of stuff to see what works best . grad d: Yeah , very much professor f: OK , before before you got put to work ? grad d: Yeah professor f: Great . OK , so that 's Sort of one branch is to get us caught up on what 's going on . Also of course it would be really nice to know what the plans are , in addition to what 's sort of already in code . professor f: and we can d I dunno w w was there  a time when we were set up to do that ? It probably will work better if we do it later in the week , after we actually understand  better what 's going on . professor f: So when do you guys leave ? phd a:  we 're here through Sunday , grad d: Oh phd a: so All through Friday would be fine . professor f: Oh , OK , so OK , So so anyt we 'll find a time later in the week to  get together and talk about your understanding of what SmartKom plans are . professor f: grad b: Should we already set a date for that ? Might be beneficial while we 're all here . I can do earlier in the day on Thursday , or  most of the time on Friday , not all . grad b: Thursday morning sounds fine ? professor f: Wha - but , Johno , phd a:   professor f: what are your constraints ? grad e:  Thursday afternoon doesn't work for me , but grad b: Neither does Thursday morning , no ? grad e:  Thursday morning should be fine . professor f: Eleven ? Eleven on Thursday ? grad e: I was just thinking I w I will have leavened by eleven . grad b: but  David is here and he 's actually knows everything about the SmartKom recognizer . grad b: OK so facing to to what we 've sort of been doing here  well for one thing we 're also using this room to collect data . grad b: no not meeting data but sort of sort ah our version of a wizard experiment such not like the ones in Munich but pretty close to it . grad b: The major difference to the Munich ones is that we do it via the telephone phd a: OK . grad b: even though all the recording is done here and so it 's a sort of a computer call system that gives you tourist information phd a:   and part of that is sort of trying to find out whether people change their linguistic verbal behavior when first thinking they speak to a machine and then to a human . grad b: and we 're setting it up so that we can we hope to implant certain intentions in people . For example  we have first looked at a simple sentence that " How do I get to the Powder - Tower ? " OK so you have the castle of Heidelberg phd a: OK . grad b: and  so What will you parse out of that sentence ? Probably something that we specified in M - three - L , that is @ @ " action go to whatever domain , object whatever Powder - Tower " . grad b: And maybe some model will tell us , some GPS module , in the mobile scenario where the person is at the moment . And  we 've sort of gone through that once before in the Deep Mail project and we noticed that first of all what are I should 've brought some slides , but what our So here 's the tower . And our system led people here , to a point where they were facing a wall in front of the tower . There is no entrance there , but it just happens to be the closest point of the road network to the geometric center Because that 's how the algorithm works . So we took out that part of the road network as a hack and then it found actually the way to the entrance . But what we actually observed in Heidelberg is that most people when they want to go there they actually don't want to enter , because it 's not really interesting . grad b: And so what   a s you s let 's say a simple parse from a s from an utterance won't really give us is what the person actually wants . Does he wanna go there to see it ? Does he wanna go there now ? Later ? How does the person wanna go there ? Is that person more likely to want to walk there ? Walk a scenic route ? and so forth . There are all kinds of decisions that we have identified in terms of getting to places and in terms of finding information about things . And we are constructing and then we 've identified more or less the extra - linguistic parameters that may f play a role . And we also want to look closely on the linguistic information that what we can get from the utterance . That 's part of why we implant these intentions in the data collection to see whether people actually phrase things differently whether they want to enter in order to buy something or whether they just wanna go there to look at it . And  so the idea is to construct   suitable interfaces and a belief - net for a module that actually tries to guess what the underlying intention was . And then enrich or augment the M - three - L structures with what it thought what more it sort of got out of that utterance . So if it can make a good suggestion , " Hey ! " you know , " that person doesn't wanna enter . That person just wants to take a picture , " cuz he just bought film , or " that person wants to enter because he discussed the admission fee before " . Or " that person wants to enter because he wants to buy something and that you usually do inside of buildings " and so forth . These ah these types of  these bits of additional information are going to be embedded into the M - three - L structure in an sort of subfield that we have reserved . If not you know , then that 's also something  that we can't really at least we want to offer the extra information . grad b:  t s Ultimately if you have if you can offer that information , somebody 's gonna s do something with it sooner or later . grad e: What was he saying ? grad b: for example , right now I know the GIS from email is not able to calculate these viewpoints . So that 's a functionality that doesn't exist yet to do that dynamically , phd a:   grad b: but if we can offer it that distinction , maybe somebody will go ahead and implement it . Surely nobody 's gonna go ahead and implement it if it 's never gonna be used , so . What have I forgotten about ? Oh yeah , how we do it , professor f: Well th  grad b: yeah that 's the professor f: No no . I s I see questions on peoples ' faces , so why don't phd a: Oh professor f: let 's let 's Let 's hear phd a: Well the obvious one would be if if you envision this as a module within SmartKom , where exactly would that Sit ? That 's the d grad b:  so far I 've thought of it as sort of adding it onto the modeler knowledge module . grad b: but it could sit anywhere in the attention - recognition  basically this is what attention - recognition literally sort of can phd a: Well it 's supposed to do . phd a: Well f from my understanding of what the people at Phillips were originally trying to do doesn't seem to quite fit into SmartKom currently so what they 're really doing right now is only selecting among the alternatives , the hypotheses that they 're given enriched by the domain knowledge and the  discourse modeler and so on . Is there other other things that cuz we wanna not Pa - pass over any you know , questions or concerns that you have . phd a: Well there 're there 're two levels of of giving an answer and I guess on both levels I don't have any  further questions . phd a:  the the two levels will be as far as I 'm concerned as  standing here for the generation module grad d: Mmm . phd a: and the other is is my understanding of what SmartKom  is supposed to be professor f: Right . phd a: and I I think that fits in perfectly professor f: So well , let me Let me s expand on that a little bit from the point of view of the generation . professor f: So the idea is that we 've actually got this all laid out an and we could show it to you ig  Robert didn't bring it today but there 's a a belief - net which is There 's a first cut at a belief - net that that doesn't it isn't fully  instantiated , and in particular some of the the combination rules and ways of getting the the conditional probabilities aren't there . professor f: There are only three possibilities and the  what one would like is for this  , knowledge modeling module to add which of those it is and give it to the planner . professor f: But ,  th the current design suggests that if it seems to be an important decision and if the belief - net is equivocal so that it doesn't say that one of these is much more probable than the other , then an option is to go back and ask for the information you want . For the debugging we 'll probably just have a a drop - down menu and the while you 're debugging you will just OK . But for a full system , then one might very well formulate a query , phd a:   professor f: give it to the dialogue planner and say this , you know ar are you know you are you planning to enter ? Or whatever it whatever that might be . So that 's under that model then , There would be a   a loop in which this thing would formulate a query , phd a: Yes . professor f: OK so , th that  , We probably won't do this early on , because the current focus is more on the decision making and stuff like that . professor f: But While we 're on the subject I just wanted to give you a sort of head 's up that it could be that some months from now we said " OK we 're now ready to try to close that loop " in terms of querying about some of these decisions . So my suggestion then is that you  look into the currently ongoing discussion about how the action plans are supposed to look like . And they 're currently  Agreeing or or in the process of agreeing on an X M L - ification of  something like a state - transition network of how dialogues would proceed . D did you know this Robert ? grad b:  Michael is doing that , right ? phd a: Well  Marcus Lerkult is actually implementing that stuff and Marcus and Michael together are  leading the discussion there , yeah . professor f: And it may be that that  we should early on make sure that they have the flexibility that we need . But they  Have I understood this right ? They they govern more or less the the dialogue behavior or the action phd a:   grad b: It 's not really what you do with the content of the dialogue but it 's So ,  there is this this this nice interf grad d: No , it 's it 's also a quantrant   grad b: i Is it professor f: So there 's ac so there th the word " action " , OK , is is what 's ambiguous here . professor f: So ,  one thing is there 's an actual planner that tells the person in the tourist domain now , phd a: OK . professor f: per tells the person how to go , " First go here , grad d:   So that 's that form of planning , and action , and a route planner and GIS , all sort of stuff . No , in SmartKom terminology that 's  called a function that 's modeled by a function modeler . That 's simply a functionality that you give data as in a query and then you get back from that mmm , a functioning model  which might be a planner or a VCR or whatever . professor f: I think tha I think it 's not going to I think that 's not going to be good enough . So I think the idea of having a , you know , transition diagram for the grammar of conversations is a good idea . professor f: OK ? And I think that we do hav definitely have to get in on it and find out OK . But I think that  when so , when you get to the tourist domain it 's not just an information retrieval system . professor f: Right ? So this i this is where I think this people are gonna have to think this through a bit more carefully . professor f: So , if it 's only like in in the in the film and T V thing , OK , you can do this . professor f: y y your I d I think the notion of this as a self contained  module you know th the functional module that that interacts with with where the tourism g stuff is going probably is too restrictive . professor f: Now I dunno how much people have thought ahead to the tourist domain in this phd a: Probably not enough ,  an another  more basic point there is that the current  tasks and therefore th the concepts in this ac what 's called the action plan and what 's really the dialogue manager . professor f: Yeah phd a:  is based on slots that have to be filled and the  kind of values in these slots would be fixed things like the a time or a movie title or something like this professor f:   phd a: and I 'm not sure if if complex slots of that type are really  being taken into consideration . phd a: So that 's that 's really something we professor f: Could you could you put a message into the right place to see if we can at least ask that question ? phd a:   phd a:  nothing 's being completely settled there grad b: rea yep phd a: so this is really an ongoing discussion grad b:  -  phd a: and that 's grad b: yeah and  it might actually OK ah also because  again in in Deep Map we have faced and implemented those problems once already phd a:   grad b: And  mmm You don't know OK th I 'll I 'll talk to Michael it 's what I do anyway . Who How far is the  the the M - three - L specification for for the la natural language input gone on the the  I haven't seen anything for the  tourist path domain . grad b: right ?  together with the usual gang ,  Petra and Jan grad d: Mmm . Yeah , there 's a meeting next next week I think grad b: OK because That 's Those are the I think the the true key issues is how does the whatever comes out of the language input pipeline look like and then what the action planner does with it and how that is  specified . I didn't think of the internal working of the  the action planner and the language  the function model as sort of relevant . But  the internal workings of of the whether you know there 're dialogue action planners that work with belief - nets that are action planners that work with you know state automata .  it does matter because it does have to keep track of you we are on part six of r a route that consists of eight steps and so forth phd a: Right . OK , so that  , for example , the i it 's the action planner is going to take some spec and s make some suggestions about what the user should do . What the user says after that is going to be very much caught up with what the action planner told it . professor f: If the If the parser and the language end doesn't know what the person 's been told OK th it 's you 're making your life much more difficult than it has to be . professor f: Right ? So if someone says the best t to  go there is by taxi , let 's say . OK , there 's all sorts of dialogues that won't make any sense which would be just fine . professor f:  phd a: That would b but that I think that that  point has been realized and it 's it 's not really  been defined yet but there 's gonna be some kind of feedback and input from  the action planner into all the analysis modules , telling them what to expect and what the current state of the discourse is . professor f: Yeah , but this is not the st this is not just the state of the discourse . professor f: OK so it z and s  , It 's great if people are already taking that into account . professor f:  I think you 're gonna need We talked about this several times that that the the input end is gonna need a fair amount of feedback from the planning end . phd a:  professor f: In in one of these things which are are much more continuous than the just the dialogue over movies and stuff . phd a: And even on on a more basic level the the action planner actually needs to be able to have  an expressive power that can deal with these structures . And not just  say   the dialogue  will consist of ten possible states and th these states really are fixed in in a certain sense . professor f:  ? phd a: You have to professor f: Would there be any chance of getting the terminology changed so that the dialogue planner was called a " dialogue planner " ? Because there 's this other thing The o There 's this other thing in in the tourist domain which is gonna be a route planner phd a: That 'd be nice . professor f: Huh ? So , s So what would happen if we sent a note saying " Gee we 've talked about this and couldn't we change this  th the whole word ? " I have no idea how complicated these things are . phd a: and I think this is just for historical reasons within  , the preparation phase of the project and not because somebody actually believes it ought to be action planner . So if there is resistance against changing it , that 's just because " Oh , We don't want to change things . professor f: Yeah , but that 's not g eh tha That ha has all the wrong connotations . I think you can't it 's fine for looking up when T you know when the show 's on TV . You go to th but I I I I think it 's really really wrong headed for something that you that has a lot of state , it 's gonna interact co in a complicated way with the  understanding parts . Yeah I think just the the spatial planner and the route planner I showed you once the interac action between them among them in the deep map system professor f: Right . grad b: so a printout of the communication between those two fills up I don't know how many pages phd a:  grad b: and that 's just part of how do I get to one place . Markus phd a: Wh - where 's ? grad b: Is he new in the in the ? phd a: Yeah , he 's he started  I think January . grad b: Is he gonna continue with the old  thing ? phd a: No , no he 's completely gonna rewrite everything . grad b: Yes I was just that 's my next question phd a:  grad b: whether we 're we 're gonna stick to Prolog or not . grad b: OK But I do think the the function modeling concept has a certain makes sense in a in a certain light phd a: Yeah . grad b: because the action planner should not be or the dialogue manager in that case should not  w have to worry about whether it 's interfacing with  something that does route planning in this way or that way phd a:   grad b: and it cant sort of formulate its what it wants in a in a rather a abstract  way , you know f " Find me a good route for this . grad b: It doesn't really have to worry ab how route planner A or how route planner B actually wants it . It 's tricky because one could well imagine I think it will turn out to be the case that  , this thing we 're talking about , th the extended n  knowledge modeler will fill in some parameters about what the person wants . One could well imagine that the next thing that 's trying to fill out the detailed  , route planning , let 's say , will also have questions that it would like to ask the user . You could well imagine you get to a point where it 's got a a choice to make and it just doesn't know something . grad b:  professor f: And a I a a good design would would allow that to happen . professor f: If if you know if if you can't make it happen then you you do your best . phd a: Yeah but that doesn't necessarily contradict  an architecture where there really is a pers a def well - defined interface . But but what it nee but th what the point is the in that case the dialogue manager is sort of event driven . So the dialogue manager may think it 's in a dialogue state of one sort , phd a:   professor f: and this one of these planning modules comes along and says " hey , right now we need to ask a question " . phd a: Sure , professor f: It could be y phd a: ye yeah I I think that 's that 's the  concept that people have , professor f: Yeah , yeah it it phd a: yep . phd a: And and the the underlying idea of course is that there is something like kernel modules with kernel functionality that you can plug  certain applications like tourist information or  the home scenario with  controlling a VCR and so on . So wouldn't That 's an additional reason to have this well - defined interface and keep these things like  tourist information external . phd a: But of course the the more complex grad b: Yeah , there is another philosophical issue that I think you know you can evade phd a: yep . grad b: but , at at least it makes sense to me that sooner or later  a service is gonna come and describe itself to you . and that 's sort of what Srini is working on in in in the DAML  project where  you you find a GIS about that gives you information on Berkeley , phd a: Yeah . grad b: and it 's it 's gonna be there and tell you what it can do and how it wants to do things . and so you can actually interface to such a system without ever having met it before and the function modeler and a self - description of the  external service haggle it out phd a:  . grad b: and you can use the same language core , understanding core to interface with planner - A , planner - B , planner - C and so forth . grad b: Which is , you know ,   utopian completely utopian at the moment , but slowly , you know , getting into the realm of the  contingent . And language input for example , is of course  crucial you know also when you do the sort of deep understanding analysis that we envision .  Then of course , the   , you know what is it poverty of the stimulus , yet the m  the less we get of that the better . and  so we we 're thinking , for example how much syntactic analysis actually happens already in the parser . Yeah , are there currently is  no syntactic analysis but in the next release there will be some . grad d: unless professor f: How 's it grad d: and it 's   you can access this professor f: S so  y we we looked at the e current pattern matching thing .  , So what are what are the plans roughly ? grad d:  it 's to to integrate and syntactic analysis . So then an utter more than one utterance is There  there 's often  pause between it and a segmentation occurs .  professor f: So , the  So the idea is to  have a pa y y a particular grad d: yeah professor f: Do you have a particular parser in mind ? Is it  partic d  have you thought through ? Is it an HPSG parser ? Is it a whatever ? grad d: No no it 's  I think it 's it 's totally complicated for it 's just one one person professor f: OK . grad d: and so I have to keep the professor f: Oh , you have to do it . grad d: ah and so things must be simpler professor f: I see , grad d: but  , Miel syntactic analysis with  finite state transducers . grad d: Yeah ,  the problem is th that it has to be very fast because  if you want to for more than one path anywhere professor f: OK . grad d: what 's in the latches from the speech recognizer professor f:   So ,  So there was a chunk parser in Verbmobil , that was one of the  branchers . And I know one of them was a chunk parser and I don't remember who did that . grad b: A Alan ? grad d: I think it 's that might , at Tuebingen I thought . grad d: was Do you know something about that ? phd a: Tubingen was at least involved in putting the chunks together grad d: In Tub - at phd a: I can't quite recall whether they actually produced the chunks in the first place . phd a: Or wh grad d: Oh from from Stuttgart , professor f: There w That 's right . They w They had There were This was done with a two phase thing , where the chunk parser itself was pretty stupid grad d: yeah , also professor f: and then there was a kind of trying to fit them together that h used more context . Yeah professor f: Right ? phd a: Well you s and and especially you did some some  , l  was a learning - based approach which learned from a big corpus of of trees . phd a: And yes the it the chunk parser was a finite - state machine that  Mark Light originally w worked on in while he was in Tuebingen professor f: Right . professor f: But is that the kind of thing y It sounds like the kind of thing that you were thinking of . yeah that 's In this direction , yes professor f: What ? grad d: Yeah , it 's in in this direction . grad b: From Michael Strube , I 've heard very good stuff about the chunk parser that is done by FORWISS , which is in embassy doing the parsing . grad b: So this is sort of came as a surprise to me that you know , embassy s is featuring a nice parser but it 's what I hear . grad b: And they 're doing chunk parsing and it 's  I I can give you the names of the people who do it there . But But  given th the constraints , that you want it to be small and fast and so forth , my guess is you 're probably into some kind of chunk parsing . And  I 'm not a big believer in this  statistical you know , cleaning up  It That seems to me kind of a last resort if  you can't do it any other way . professor f: There is this this one that they did at SRI some years ago Fastus ? grad d:  professor f: a grad d: yeah , I 've I 've looked at it but but it 's no not much  information available . I found , professor f: ah ! grad d: but it 's also finite - state transducers , I thought . grad d: and professor f: And of course it was English oriented , grad d: Yeah , and and Purely finite - state transducers are not so good for German since there 's  professor f:  w Right . grad d: The word order is is  not fixed professor f: Yeah , I guess that 's the point is is all the morphology and stuff . Also it 's  it 's  Yes ,  the  choice between  this processing and that processing and my template matcher . grad d:  professor f: So what about  Did y like Morfix ? a a e y you 've got stemmers ? Or is that something that grad d: yeah but it 's all in the in the lexicon . So it 's professor f: But did you have that ? grad d: Yeah th the information is available . So , but grad d: So professor f: So y you just connect to the lexicon grad d: Yeah professor f: and  at least for German you have all all of the  the stemming information . grad d: It  professor f: Did we look at the German ? I don't remember . professor f: So w wha phd a: n Well I think I think there 's some misunderstanding here professor f: i phd a: it 's Morphix is not used on - line . phd a: s so the lexicon might be derived by Morphix grad d: What ? phd a: but What what 's happening on - line is just   a a retrieval from the lexicon which would give all the stemming information professor f: Right . professor f: What  I didn't reme grad b: We threw out all the forms professor f: Huh ? grad b: because , you know , English , well professor f: Oh OK , so it yeah , s s I thought I 'd grad d:   professor f: So in German then you actually do case matching and things like in the in the pattern matcher or not ? grad d:  Not yet but it 's planned to do that . grad d: Yeah professor f: Have we looked at the German ? Oh , I haven yeah that 's getting it from the lexicon is just fine . In terms of if you 're trying to build some fast parser and so forth and You really might wanna do it in a significantly different way . So you 've you guys have looked at this ? also ? in terms of You know , w if you 're doing this for English as well as German  Do you think now that it would be this doing it similarly ? grad d:  Yeah , it 's  I think it 's  yes , it 's it 's  possible to to do list processing . grad b: Well there 's m I 'm sure there 's gonna be more discussion on that after your talk . grad d:  -  , grad b: We 're just gonna foreshadow what we saw that grad d: yeah . grad b: and  professor f: Now actually ,  Are you guys free at five ? Or Do you have to go somewhere at five o ' clock tonight ? W in ten minutes ? grad d: Ah phd a:   I think we 're expect grad d: mmm . professor f: That 's good , because that will  tell you a fair amount about The form of semantic construction grammar that we 're using . professor f: so So I th I think that probably as good an introduction as you 'll get . professor f: It won't talk particularly about how that relates to what  Robert was saying at the beginning . So we talked about the fact that There 're going to be a certain number of decisions That you want the knowledge modeler to make , that will be then fed to the function module , that does  , route planning . And then one half of this we talked about at little bit is how if you had the right information , if you knew something about what was said and about th the something about was the agent a tourist or a native or a business person or  young or old , whatever . That information , and also about the  , what we 're calling " the entity " , Is it a castle , is it a bank ? Is it a s town square , is it a statue ? Whatever . But the other half of the problem is How would you get that kind of information from the parsed input ? So ,  So what you might try to do is just build more templates , saying  we 're trying to build a templ you know build a template that w  somehow would capture the fact that he wants to take a picture . But  from our point of view this is also a research project and there are a couple of people not here for various reasons who are doing doctoral dissertations on this , phd a:   professor f: and the idea that we 're really after is a very deep semantics based on cognitive linguistics and the notion that there are a relatively small number of primitive conceptual schemas that characterize a lot of activity . But also , importantly for Lakoff and these guys is all sorts of metaphorical things are also characterized this way . professor f: and so s So , what we 're really trying to do is to map from the discourse to the conceptual semantics level . professor f: So another one of these primitive , what are called " image schemas " , is  goal seeking . professor f: And that all sorts of things , particularly in the tourist domain , can be represented in terms of  source , path and goal . So the idea would be could we build an analyser that would take an utterance and say " Aha ! th this utterance is talking about an attempt to reach a goal . The goal is this , the pers the ,  traveller is that ,  the sor w where we are at now is is this , they 've mentioned possible obstacles , et cetera . So if you can do this , then the notion would be that across a very large range of domains , you could use this deep conceptual basis as the interface . professor f: And then ,  The processing of that , both on the input end , recognizing that certain words in a language talk about containers or goals , et cetera , and on the output end , given this kind of information , you can then  make decisions about what actions to take . professor f: And Nancy is going to Her talk is going to be not about using this in applications , but about modeling how children might learn this kind of  deep semantic grammar . Would it be highly ambiguous if and then there would be another module that takes that  highly underspecified deep semantic construction and map it onto the current context to find out what the person really was talking about in that context . or or a professor f: Well that 's that 's that 's where the belief - net comes in . professor f: So part of what you 'll get out of this will be the fact tha w if it works right , OK , that this is an agent that wants to go to this place and that 's their goal phd a:   professor f: OK , phd a: th professor f: part of it comes from the ontology . professor f: And the idea of the belief - net is it combines the information from the dialogue which comes across in this general way , phd a:   professor f: you know this is a this is a goal seeking behavior , along with specific information from the ontology about the kinds of objects involved phd a: Yeah OK , Yeah , yep yep yep yep professor f: and about the situation about " Is it raining ? " I don't know . professor f: And so th the coupling to the situation comes in this model from , at th at th at the belief - net , combining evidence from the dialogue with the ontology with the situation . professor f: But Nancy isn't gonna talk about that , phd a: Yeah , oh yeah , I see , professor f: just about the  phd a: yeah yeah , really . phd g: Is it i in , then , your place , in five five - A ? phd a: Alright .