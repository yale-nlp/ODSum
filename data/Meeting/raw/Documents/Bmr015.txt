grad b: We didn't crash we 're not crashing anymore phd c: One , two , three , four , f grad b: and it really bothers me . phd c: Yeah ? professor a: Oh ! Well maybe it 's just , you know , how many t u u u u how many times you crash in a day . phd g: Or maybe it 's once you 've done enough meetings it won't crash on you anymore . professor a: Do we have an agenda ? Liz Liz and Andreas can't sh can't  , can't come . phd g: Did they send , the messages to you about the meeting today ? grad b: I have no idea but I just got it a few minutes ago . grad b: So , does anyone have any a agenda items other than me ? I actually have one more also which is to talk about the digits . professor a: right , so so I I was just gonna talk briefly about the NSF ITR . professor a: and then , you have postdoc f: Can w professor a: I won't say much , but  , but then , you said wanna talk about digits ? grad b: I have a short thing about digits and then  I wanna talk a little bit about naming conventions , although it 's unclear whether this is the right place to talk about it . So maybe just talk about it very briefly and take the details to the people who for whom it 's relevant . I 've been but but  , well professor a: Well if we Yeah , we shouldn't add things in just to add things in . grad b: So the only thing I wanna say about digits is , we are pretty much done with the first test set . There are probably forms here and there that are marked as having been read that weren't really read . So I won't really know until I go through all the transcriber forms and extract out pieces that are in error . The first is what should we do about digits that were misread ? My opinion is , we should just throw them out completely , and have them read again by someone else . grad b: so it it 's perfectly fine to put a a group together again of errors and have them re - read , just to finish out the test set . postdoc f: Oh ! By throw them out completely ? grad b: the other thing you could do is change the transcript to match what they really said . I know I 've done it , where I say say a grad b: What the transcribers did with that is if they did a correction , and they eventually did read the right string , you extract the right string . phd g: Oh , you 're talking about where they completely read the wrong string and didn't correct it ? phd e: Yeah . grad b: So so postdoc f: Well , and s and you 're talking string - wise , you 're not talking about the entire page ? grad b: Correct . grad b: And so the the two options are change the transcript to match what they really said , but then but then the transcript isn't the Aurora test set anymore . phd g: Well how many are how how often does that happen ? grad b: Mmm , five or six times . professor a: Yeah , it 's five or six times out of thousands ? phd c: Yeah . phd g: Yeah , it 's professor a: Yeah , I would , tak do the easy way , phd g: Yeah . professor a: It it 's kinda nice  , wh who knows what studies people will be doing on on speaker - dependent things phd c: Mmm . phd g: So you  , how many digits have been transcribed now ? grad b: Four thousand lines . phd g: Four thousand lines ? grad b: I didn't I didn't compute the average . grad b: And , Jane , I do have a set of forms which I think you have copies of somewhere . grad b: Yeah , I was just wond I thought I had had all of them back from you . And then the other thing is that , the forms in front of us here that we 're gonna read later , were suggested by Liz postdoc f: No , not yet . And so , I just wanted people to , take a quick look at the instructions phd c:   grad b: and the way it wa worked and see if it makes sense and if anyone has any comments on it . Although we could switch it back and tell them always to say " zero " or always to say " O " . professor a: that 's the only thought I have because if you t start talking about these , you know u tr She 's trying to get at natural groupings , but it there 's there 's nothing natural about reading numbers this way . grad b: But , the other problem we were thinking about is if you just put the numerals , they might say forty - three instead of four three .  , you can With when you space them out they don't look like , forty - three anymore . grad b: and she felt that it 's very , very natural to do that sort of chunking .  it 's a it 's a it 's an interesting problem  , we 've done stuff with numbers before , and yeah sometimes people If you say s " three nine eight one " sometimes people will say " thirty - nine eighty - one " or " three hundred three hundred eighty - nine one " , or I don't think they 'd say that , phd c: Yeah . professor a: but but th grad b: Not very frequently professor a: no grad b: but , they certainly could . grad b: and , since this was something that Liz asked for specifically , I think we need to defer to her . Well , we 're probably gonna be collecting meetings for a while and if we decide we still wanna do some digits later we might be able to do some different ver different versions , grad b: Do something different , professor a: but this is the next suggestion , grad b: yeah . OK , so  e l I guess , let me , get my my short thing out about the NSF .  , I I sent to what I thought we had , in some previous mail , as the right joint thing to send to , which was " M MTG RCDR hyphen joint " . professor a: But then I got some sort of funny mail saying that the moderator was going to grad b: It 's That 's because they set the one up at UW postdoc f:  grad b: that 's not on our side , that 's on the U - dub side . grad b: And , I have no idea whether it actually ever goes to anyone so you might just wanna mail to Mari professor a: No no , th I got I got , little excited notes from Mari and Jeff and so on , grad b: and professor a: so it 's grad b: OK , good . grad b: Cuz I had sent one earlier Actually the same thing happened to me I had sent one earlier . The message says , " You 'll be informed " and then I was never informed but I got replies from people indicating that they had gotten it , so . Well , anyway , I guess everybody here Are y are you are on that list , right ? So you got the note ? phd g:   professor a: so this was , a , proposal that we put in before on on more more higher level , issues in meetings , from I guess higher level from my point of view .  , and , meeting mappings , and ,  so is i for it was a proposal for the ITR program , Information Technology Research program 's part of National Science Foundation . They 're they 're a lot of them are some of them anyway , are larger larger grants than the usual , small NSF grants , and . So , they 're very competitive , and they have a first phase where you put in pre - proposals , and we we , got through that . grad b: When 's when 's the full proposal due ? professor a: I think April ninth , or something . And they said end of business day you could check on the reviewer forms , phd g: u grad b: is that phd g: Tomorrow . grad b: I guess that 's a good thing cuz that way I got my papers done early . phd g: It would be interesting professor a: So that 's amazing you showed up at this meeting ! grad b: It is . My favorite is was when when when one reviewer says , " you know , this should be far more detailed " , and the nex the next reviewer says , " you know , there 's way too much detail " . Or " this is way too general " , and the other reviewer says , " this is way too specific " . Is that right ? That they didn't reject a lot of the pre - proposals ? professor a: Do you know anything about the numbers ? grad b: No . phd g: Gary Strong 's professor a: I phd g: there was a sentence at the end of one of his paragraphs phd e: Yeah . He said the next phase 'll be very , competitive phd e: Very very , phd g: because we didn't want to weed out much in the first phase . professor a: So , you know , maybe they didn't r weed out as much as usual , but it 's it 's usually a pretty But it Yeah . It 's it 's certainly not I 'm sure that it 's not down to one in two or something of what 's left . professor a: I 'm sure it 's , you know grad b: How how many awards are there , do you know ? professor a: Well there 's different numbers of w awards for different size They have three size grants . This one there 's ,  See the small ones are less than five hundred thousand total over three years and that they have a fair number of them .  , and the large ones are , boy , I forget , I think , more than , more than a million and a half , more than two million or something like that . But , I don't remember , but it 's pr probably along the li I I could be wrong on this yeah , but probably along the lines of fifteen or that they 'll fund , or twenty .  when they Do you do you know how many they funded when they f in in Chuck 's , that he got last year ? phd g: I don't I don't know . grad b: I thought it was smaller , that it was like four or five , wasn't it ? professor a: Well they fund phd g: I I 'm professor a: they phd g: I don't remember . professor a: and this time they came up with a middle one , so it 'll there 'll be more of them that they fund than of the big . phd g: If we end up getting this , what will it mean to ICSI in terms of , w wh where will the money go to , what would we be doing with it ? professor a:  . professor a: You know , it i None of it will go for those yachts that we 've talking about . phd g:  Dang ! professor a: well , no ,  it 's u It phd g: It 's just for the research to continue the research on the Meeting Recorder stuff ? professor a: It 's extending the research , right ? Because the other phd g: Yeah . grad b: Yeah it 's go higher level stuff than we 've been talking about for Meeting Recorder . Yeah the other things that we have , been working on with , the c with Communicator  , especially with the newer things with the more acoustically - oriented things are are are are lower level . And , this is dealing with , mapping on the level of of , the conversation of mapping the conversations phd g:   So it 's all it 's all stuff that none none of us are doing right now , or none of us are funded for , so it 's so it 's it would be new . phd g: So assuming everybody 's completely busy now , it means we 're gonna hafta , hire more students , or , something ? professor a: Well there 's evenings , and there 's weekends , and  . Yeah , there there would be there would be new hires , and and there there would be expansion , but , also , there 's always for everybody there 's there 's always things that are dropping off , grants that are ending , or other things that are ending , so , phd g: Right . professor a: But but there definitely would be new new new , students , phd g: I see . grad b: Are there any students in your class who are expressing interest ? professor a: not clear yet . professor a:  we got we have yeah , two of them are two in the c There 're two in the class already here , and then and and , then there 's a third who 's doing a project here , who ,  But he he he won't be in the country that long , grad b:   professor a: Actually there is one other guy who 's looking that that 's that guy , Jeremy ? I think .  professor a: Anyway , yeah that 's that 's all I was gonna say is that that that 's you know , that 's nice and we 're sorta preceding to the next step , and , it 'll mean some more work , you know , in in March in getting the proposal out , and then , it 's , you know We 'll see what happens . It just ,  we 've been cutting up sound files , in for ba both digits and for , doing recognition . And Liz had some suggestions on naming and it just brought up the whole issue that hasn't really been resolved about naming . So , one thing she would like to have is for all the names to be the same length so that sorting is easier . grad b: same number of characters so that when you 're sorting filenames you can easily extract out bits and pieces that you want . And I don't think we have so many meetings that that 's a big deal just to change the names . So that means , instead of calling it " MR one " , " MR two " , you 'd call it " MRM zero zero one " , " MRM zero zero two " , things like that . postdoc f: But , you know , when you , do things like that you can always as long as you have  , you can always search from the beginning or the end of the string . postdoc f: You know , so " zero zero two " grad b: Alright , postdoc f: Yeah . grad b: so we we have th we 're gonna have the speaker ID , the session , information on the microphones , postdoc f: Yeah , well , your example was really grad b: information on the speak on the channels and all that . postdoc f: i grad b: And so if each one of those is a fixed length , the sorting becomes a lot easier . So like , the NSA meeting lengths , all filenames are gonna be the same length as the Meeting Recorder meeting names ? grad b: Yep . And as I said , the it 's we just don't have that many that that 's a big deal . grad b: And so , at some point we have to sort of take a few days off , let the transcribers have a few days off , make sure no one 's touching the data and reorganize the file structures . postdoc f: I I would think though that the transcribe the transcripts themselves wouldn't need to have such lengthy names . postdoc f: So , you 're dealing with a different domain there , and with start and end times and all that , and channels and stuff , grad b: Right . So the only thing that would change with that is just the directory names , postdoc f: so , it 's a different set . grad b: So for for m the meetings we were thinking about three letters and three numbers for meeting I Ds .  , for speakers , M or F and then three numbers , For ,  and , that also brings up the point that we have to start assembling a speaker database so that we get those links back and forth and keep it consistent . We want some way of specifying , more than looking in the " key " file , what channel and what mike . grad b: that 's gonna become especially important once we start changing the microphone set - up . We have some new microphones that I 'd like to start trying out , once I test them . professor a: since we have such a short agenda list I guess I wi I will ask how how are the transcriptions going ? Yeah . postdoc f: The the news is that I 've I  s So in s  So I 've switched to Start my new sentence . I I switched to doing the channel - by - channel transcriptions to provide , the  , tighter time bins for partly for use in Thilo 's work and also it 's of relevance to other people in the project . And , I discovered in the process a couple of of interesting things , which , one of them is that , it seems that there are time lags involved in doing this , using an interface that has so much more complexity to it . And I and I wanted to maybe ask , Chuck to help me with some of the questions of efficiency . Maybe I was thinking maybe the best way to do this in the long run may be to give them single channel parts and then piece them together later .  , so it 's like , I I know that I can take them apart and put them together and I 'll end up with the representation which is where the real power of that interface is . postdoc f: And it may be that it 's faster to transcribe a channel at a time with only one , sound file and one , set of of , utterances to check through . I thought that that one of the reason we thought we were so much faster than than , the the other transcription , thing was that that we were using the mixed file . But , with the mixed , when you have an overlap , you only have a a choice of one start and end time for that entire overlap , which means that you 're not tightly , tuning the individual parts th of that overlap by different speakers . postdoc f: So someone may have only said two words in that entire big chunk of overlap . postdoc f: And for purposes of of , things like well , so things like training the speech - nonspeech segmentation thing . postdoc f: And w and w and , you know , is a It would be wonderful if , it 's possible then to use that algorithm to more tightly tie in all the channels after that but , you know , I 've th the So , I I don't know exactly where that 's going at this point . But m I was experimenting with doing this by hand and I really do think that it 's wise that we 've had them start the way we have with , m y working off the mixed signal , having the interface that doesn't require them to do the ti  , the time bins for every single channel at a t  , through the entire interaction . postdoc f: I did discover a couple other things by doing this though , and one of them is that , once in a while a backchannel will be overlooked by the transcriber . postdoc f: because when it 's a b backchannel could well happen in a very densely populated overlap . And if we 're gonna study types of overlaps , which is what I wanna do , an analysis of that , then that really does require listening to every single channel all the way through the entire length for all the different speakers . Now , for only four speakers , that 's not gonna be too much time , but if it 's nine speakers , then that i that is more time . So it 's li you know , kind of wondering And I think again it 's like this it 's really valuable that Thilo 's working on the speech - nonspeech segmentation because maybe , we can close in on that wi without having to actually go to the time that it would take to listen to every single channel from start to finish through every single meeting .  especially if they 're really short and they 're not very loud and so it it can it it will always happen that also the automatic s detection system will miss some of them , so . Well so then then , maybe the answer is to , listen especially densely in places of overlap , phd e: Yeah . postdoc f: just so that they 're they 're not being overlooked because of that , and count on accuracy during the sparser phases . postdoc f: Cuz there are large s spaces of the That 's a good point . I I think it 's really interesting data to work with , I have to say , it 's very enjoyable .  , you 're you 're you 're still in the midst of what you 're doing from what you described last time , I assume , phd c: Is true . postdoc f:  professor a: and phd c: I haven't results , eh , yet professor a: Yeah . phd c: but , eh , I I 'm continue working with the mixed signal now , after the the last experience . phd c: And and I 'm tried to to , adjust the to to improve , eh , an harmonicity , eh , detector that , eh , I I implement . phd c: But I have problem because , eh , I get , eh , eh , very much harmonics now . phd c: harmonic possi possible harmonics , eh , and now I 'm I 'm I 'm trying to to find , eh , some kind of a ,  of h of help , eh , using the energy to to distinguish between possible harmonics , and and other fre frequency peaks , that , eh , corres not harmonics . And , eh , I have to to talk with y with you , with the group , eh , about the instantaneous frequency , because I have , eh , an algorithm , and , I get , mmm , eh , t t results similar results , like , eh , the paper , eh , that I I am following . But , eh , the the rules , eh , that , eh , people used in the paper to to distinguish the harmonics , is doesn't work well . phd c: And I I I I not sure that i eh , the the way o to ob the way to obtain the the instantaneous frequency is right , or it 's it 's not right . If if if ,  If I don't have enough time and y you wanna discuss with someone else some someone else besides us that you might want to talk to , might be Stephane . phd c: and , professor a: Yeah , but phd c: they nnn they they they didn't phd e: I 'm not too experienced with harmonics professor a: I see . phd c: they think that the experience is not enough to phd e: and phd g: Is is this the algorithm where you hypothesize a fundamental , and then get the energy for all the harmonics of that fundamental ? phd c: No , no it 's No No . phd g: And then hypothesize a new fundamental and get the energy professor a: Yeah , that 's wh phd c: No . phd c: And The algorithm said that , eh , if you if you change the the the , eh , nnn the X - the frequency " X " , eh , using the in the instantaneous frequency , you can find , eh , how , eh , in several frequencies that proba probably the the harmonics , eh , professor a:  - huh . phd c: the errors of peaks the frequency peaks , eh , eh , move around these , eh eh frequency harmonic the frequency of the harmonic . And , eh , if you if you compare the the instantaneous frequency , eh , of the of the , eh , continuous , eh , eh , filters , that , eh that , eh , they used eh , to to to get , eh , the the instantaneous frequency , professor a:   phd c: it probably too , you can find , eh , that the instantaneous frequency for the continuous , eh , eh the output of the continuous filters are very near . phd c: And professor a: It 's it 's it 's I haven't worked with that either so I 'm not sure The way the simple - minded way I suggested was what Chuck was just saying , is that you could make a a sieve . professor a: Let 's let 's hypothesize that it 's this frequency or that frequency , and and , maybe you maybe you could use some other cute methods to , short cut it by by  , making some guesses , phd c: Yeah . professor a: but but    , I would ,   you could make some guesses from ,  from the auto - correlation or something but but then , given those guesses , try , only looking at the energy at multiples of the of that frequency , and and see how much of the take the one that 's maximum . phd g: Do you hafta do some kind of , low - pass filter before you do that ? phd c: I don't use . phd g: Or phd c: But , I I know many people use , eh , low - pass filter to to to get , eh , the pitch . phd g: But i But the harmonics are gonna be , I don't know what the right word is .  , they 're gonna be dampened by the  , vocal tract , right ? The response of the vocal tract . professor a: Yeah ? phd c: Yeah ? phd g: And so just looking at the energy on those at the harmonics , is that gonna ? professor a: Well so the thing is that the This is for , a ,  phd g: I m what you 'd like to do is get rid of the effect of the vocal tract . professor a: But ,  but I but but I don't know that you need to grad b: Open wide ! professor a: but I don't need you know if you need to get rid of it .  that 'd that 'd be nice but I don't know if it 's ess if it 's essential .  ,  cuz I think the main thing is that , you 're trying phd g:  - huh . professor a: wha what are you doing this for ? You 're trying distinguish between the case where there is ,  where where there are more than  , where there 's more than one speaker and the case where there 's only one speaker . professor a: So if there 's more than one speaker ,  yeah I guess you could I guess yeah you 're so you 're not distinguished between voiced and unvoiced , so so , i if you don't if you don't care about that phd c: Yeah . professor a: See , if you also wanna just determine if you also wanna determine whether it 's unvoiced , then I think you want to look look at high frequencies also , because the f the fact that there 's more energy in the high frequencies is gonna be an ob sort of obvious cue that it 's unvoiced . professor a: But , i i   i i but , other than that I guess as far as the one person versus two persons , it would be primarily a low frequency phenomenon . And if you looked at the low frequencies , yes the higher frequencies are gonna there 's gonna be a spectral slope .  that 's that 's w phd c: I will prepare for the next week eh , all my results about the harmonicity and will will try to come in and to discuss here , because , eh , I haven't enough feeling to to u many time to to understand what happened with the with , eh , so many peaks , eh , eh , and I I see the harmonics there many time but , eh , there are a lot of peaks , eh , that , eh , they are not harmonics . phd c: I have to discover what what is the the w the best way to to to c to use them professor a: Well , but yeah I don't think you can  you 're not gonna be able to look at every frame , so  I  I I really I I really thought that the best way to do it , and I 'm speaking with no experience on this particular point , but , my impression was that the best way to do it was however you You 've used instantaneous frequency , whatever . However you 've come up you with your candidates , you wanna see how much of the energy is in that phd c: Yeah . And , if it 's voiced , I guess so so y I think maybe you do need a voiced - unvoiced determination too . professor a: and the ,  e the fraction of the energy that 's in the harmonic sequence that you 're looking at is relatively low , then it should be then it 's more likely to be an overlap . This this is the idea the idea I I I had to to compare the the ratio of the the energy of the harmonics with the eh , with the , eh , total energy in the spectrum and try to get a ratio to to distinguish between overlapping and speech . professor a: But you 're looking a y you 're looking at Let 's take a second with this .  , you 're looking at f at the phase derivative , in in , what domain ?  this is this is in in in in bands ? Or or phd c: No , no , no . professor a: Just just overall phd c: It 's a it 's a o i w the band the band is , eh , from zero to to four kilohertz . And I I ot I professor a: And you just take the instantaneous frequency ? phd c: Yeah . to FFT to to obtain the or to study the harmonics from from the spectrum directly , professor a: Yeah . And another another algorithm I have is the in the instantaneous frequency , based on on on the FFT to to to calculate the the phase derivate in the time . phd c: But , eh , in m i in my opinion the the the instantaneous frequency , the the the behavior , eh , was th it was very interesting . Because I I saw eh , how the spectrum concentrate , eh , professor a: Oh ! phd c: around the the harmonic . But then when I apply the the rule , eh , of the in the the instantaneous frequency of the ne of the continuous filter in the the near filter , the the rule that , eh , people propose in the paper doesn't work . professor a: But the instantaneous frequency , wouldn't that give you something more like the central frequency of the you know , of the where most of the energy is ?  , I think if you Does i does it Why would it correspond to pitch ? phd c: Yeah . phd c: When first I I calculate , eh , using the FFT , postdoc f: Di - digital camera . professor a: Oh , so you scale you s you do a a scaling along that axis according to instantaneous phd c: I use Yeah . phd c: eh , when i I I use these these frequency , eh , the range is different , and the resolution is different . phd c: But , eh , they used , eh , a rule , eh , based in the in the because to to calculate the instantaneous frequency , they use a Hanning window . phd c: And , they said that , eh , if these peak are , eh , harmonics , the f instantaneous frequency , of the contiguous , eh w eh eh , filters are very near , or have to be very near . But , eh , phh ! I don't I I I I don I I and I don't know what is the what is the distance . And I tried to to put different distance , eh , to put difference , eh eh , length of the window , eh , different front sieve , Pfff ! and I I not sure what happened . I 'll probably gonna hafta look at the paper , but which I 'm not gonna have time to do in the next few days , but but I 'm I 'm curious about it . postdoc f: I I did i it did occur to me that this is  , the return to the transcription , that there 's one third thing I wanted to to ex raise as a to as an issue which is , how to handle breaths . So , I wanted to raise the question of whether people in speech recognition want to know where the breaths are . And the reason I ask the question is , aside from the fact that they 're obviously very time - consuming to encode , the fact that there was some I had the indication from Dan Ellis in the email that I sent to you , phd e: Yeah . postdoc f: and you know about , that in principle we might be able to , handle breaths by accessi by using cross - talk from the other things , be able that in principle , maybe we could get rid of them , so maybe And I was I I don't know ,  we had this an and I didn't couldn't get back to you , phd e: Yeah . postdoc f: but the question of whether it 'd be possible to eliminate them from the audio signal , which would be the ideal situation , professor a: I don't know think it 'd be ideal . professor a: We - See , we 're we 're dealing with real speech and we 're trying to have it be as real as possible phd e: Yeah . postdoc f: Well , except that these are really truly  , ther there 's a segment in o the one I did n the first one that I did for i for this , phd e: Yeah . postdoc f: where truly w we 're hearing you breathing like as if we 're you 're in our ear , you know , and it 's like it 's like professor a: Yeah . postdoc f: I y i  , breath is natural , but not professor a: It is but it is if you record it . postdoc f: Except that we 're we 're trying to mimic Oh , I see what you 're saying . grad b: The P D A might not have to , phd e: No i grad b: but more people than just PDA users are interested in this corpus . grad b: So so mean you 're right postdoc f: OK , then the then I have two questions . grad b: we could remove it , postdoc f: Yeah ? grad b: but I I think we don't wanna w remove it from the corpus , in terms of delivering it because the people will want it in there . If if it gets in the way of what somebody is doing with it then you might wanna have some method which will allow you to block it , but you it 's real data . You don't wanna b but you don't postdoc f: OK , well professor a: If s you know , if there 's a little bit of noise out there , and somebody is is talking about something they 're doing , that 's part of what we accept as part of a real meeting , even And we have the f  the  the the fan and the in the projector up there , and , this is it 's this is actual stuff that we we wanna work with . postdoc f: because i it basically has a i it shows very clearly the contrast between , speech recognition research and discourse research because in in discourse and linguistic research , what counts is what 's communit communicative . postdoc f: And breath , you know , everyone breathes , they breathe all the time . postdoc f: and the idea is that the transcripts will that get stored as a master there 'll be a master transcript which has in it everything that 's needed for both of these uses . postdoc f: And the one that 's used for speech recognition will be processed via scripts . Discourse side will have this this side over he the we we 'll have a s ch Sorry , not being very fluent here . But , this the discourse side will have a script which will stri strip away the things which are non - communicative . So then the then let 's let 's think about the practicalities of how we get to that master copy with reference to breaths . So what I would r r what I would wonder is would it be possible to encode those automatically ? Could we get a breath detector ? grad b: Oh , just to save the transcribers time . postdoc f: and just simply the keystrokes it takes to negotiate , to put the boundaries in , to to type it in , i it 's just a huge amount of time . postdoc f: And you wanna be sure it 's used , and you wanna be sure it 's done as efficiently as possible , and if it can be done automatically , that would be ideal . professor a: what if you put it in but didn't put the boundaries ? postdoc f: Well , but professor a: So you just know it 's between these other things , postdoc f: Well , OK . So now there 's there 's another another possibility professor a: right ? postdoc f: which is , the time boundaries could mark off words from nonwords . professor a: Yeah  I 'm think if it 's too if it 's too hard for us to annotate the breaths per se , we are gonna be building up models for these things and these things are somewhat self - aligning , so if so , we i i if we say there is some kind of a thing which we call a " breath " or a " breath - in " or " breath - out " , the models will learn that sort of thing .  , so but you but you do want them to point them at some region where where the breaths really are . But that would maybe include a pause as well , phd g: Well , there 's a there 's postdoc f: and that wouldn't be a problem to have it , pause plus breath plus laugh plus sneeze ? professor a: Yeah , i You know there is there 's this dynamic tension between between marking absolutely everything , as you know , and and and marking just a little bit and counting on the statistical methods . But if there seems to be a lot of effort for a small amount of reward in some area , and this might be one like this Although I I I 'd be interested to h get get input from Liz and Andreas on this to see if they Cuz they 've - they 've got lots of experience with the breaths in in , their transcripts . grad b: They have lots of experience with breathing ? phd g: I professor a: Actually Well , yes they do , but we we can handle that without them here . But but but , you were gonna say something about phd g: Yeah , I I think , one possible way that we could handle it is that , you know , as the transcribers are going through , and if they get a hunk of speech that they 're gonna transcribe , u th they 're gonna transcribe it because there 's words in there or whatnot . But if there 's a big hunk of speech , let 's say on Morgan 's mike where he 's not talking at all , don't don't worry about that . phd g: So what we 're saying is , there 's no guarantee that ,  So for the chunks that are transcribed , everything 's transcribed . So you just somebody can't rely on that data and say " that 's perfectly clean data " .  do you see what I 'm saying ? postdoc f: Yeah , you 're saying it 's uncharted territory . phd g: So I would say don't tell them to transcribe anything that 's outside of a grouping of words . phd e: Yeah , and that 's that that quite co corresponds to the way I I try to train the speech - nonspeech detector , as I really try to not to detect those breaths which are not within a speech chunk but with which are just in in a silence region . phd e: And they so they hopefully won't be marked in in those channel - specific files . professor a: u I I wanted to comment a little more just for clarification about this business about the different purposes . professor a: See , in a in a way this is a really key point , that for speech recognition , research , e a it 's not just a minor part . In fact , the I think I would say the core thing that we 're trying to do is to recognize the actual , meaningful components in the midst of other things that are not meaningful . So it 's critical it 's not just incidental it 's critical for us to get these other components that are not meaningful . professor a: if we had only linguistically - relevant things if if we only had changes in the spectrum that were associated with words , with different spectral components , and , we we didn't have noise , we didn't have convolutional errors , we didn't have extraneous , behaviors , and so forth , and moving your head and all these sorts of things , then , actually speech recognition i i isn't that bad right now . professor a: The the the reason we still complain about it is because is when when you have more realistic conditions then then things fall apart . I guess , I  , what I was wondering is what what at what level does the breathing aspect enter into the problem ? Because if it were likely that a PDA would be able to be built which would get rid of the breathing , so it wouldn't even have to be processed at thi at this computational le well , let me see , it 'd have to be computationally processed to get rid of it , but if there were , like likely on the frontier , a good breath extractor then , and then you 'd have to professor a: But that 's a research question , you know ? And so postdoc f: Yeah , well , see and that 's what I wouldn't know .  so so the thing is it 's it right now it 's just raw d it 's just data that we 're collecting , and so we don't wanna presuppose that people will be able to get rid of particular degradations because that 's actually the research that we 're trying to feed . So , you know , an and maybe maybe in five years it 'll work really well , postdoc f: OK . professor a: and and it 'll only mess - up ten percent of the time , but then we would still want to account for that ten percent , so . postdoc f: I guess there 's another aspect which is that as we 've improved our microphone technique , we have a lot less breath in the in the more recent , recordings , so it 's in a way it 's an artifact that there 's so much on the on the earlier ones . phd g: One of the  , just to add to this one of the ways that we will be able to get rid of breath is by having models for them . phd g: And so in order to build the model you need to have some amount of it marked , so that you know where the boundaries are . phd g: So  , I don't think we need to worry a lot about breaths that are happening outside of a , you know , conversation . We don't have to go and search for them to to mark them at all , but , if they 're there while they 're transcribing some hunk of words , I 'd say put them in if possible . postdoc f: OK , and it 's also the fact that they differ a lot from one channel to the other because of the way the microphone 's adjusted 