professor c: So ,  grad f: so I wanted to discuss digits briefly , but that won't take too long . OK , agenda items , we have digits , What else we got ? phd a: New version of the presegmentation . postdoc b: do we wanna say something about the , an update of the , transcript ? phd g: Yeah , why don't you summarize the professor c: Update on transcripts . phd g: And I guess that includes some the filtering for the , the ASI refs , too . professor c: Filtering for what ? phd g: For the references that we need to go from the the fancy transcripts to the sort of brain - dead . postdoc b: It 'll it 'll be basically it 'll be a re - cap of a meeting that we had jointly this morning . OK well , the , w  as you can see from the numbers on the digits we 're almost done . You know , someone fills out the form and then they 're not at the meeting and so it 's blank . And so , once we 're it 's done it would be very nice to train up a recognizer and actually start working with this data . phd d: So we 'll have a corpus that 's the size of TI - digits ? grad f: And so One particular test set of TI - digits . grad f: So , I I extracted , Ther - there was a file sitting around which people have used here as a test set . It had been randomized and so on phd d:  grad f: and that 's just what I used to generate the order . professor c: So , I 'm impressed by what we could do , Is take the standard training set for TI - digits , train up with whatever , you know , great features we think we have ,  for instance , and then test on  this test set . grad f:  professor c: And presumably  it should do reasonably well on that , and then , presumably , we should go to the distant mike , and it should do poorly . professor c: And then we should get really smart over the next year or two , and it that should get better . grad f: so that the reason it 's not just a transcript is that there 're false starts , and misreads , and miscues and things like that . And so I have a set of scripts and X Waves where you just select the portion , hit R , it tells you what the next one should be , and you just look for that . You know , so it it 'll put on the screen , " The next set is six nine , nine two two " . And you find that , and , hit the key and it records it in a file in a particular format . professor c: So is this grad f: And so the the question is , should we have the transcribers do that or should we just do it ? Well , some of us . I 've been do I 've done , eight meetings , something like that , just by hand .  professor c: what what do you think ? postdoc b: My feeling is that we discussed this right before coffee and I think it 's a it 's a fine idea partly because , it 's not un unrelated to their present skill set , but it will add , for them , an extra dimension , it might be an interesting break for them . And also it is contributing to the , c composition of the transcript cuz we can incorporate those numbers directly and it 'll be a more complete transcript . grad f: There is there is professor c: So you think it 's fine to have the transcribers do it ? postdoc b:   grad f: There 's one other small bit , which is just entering the information which at s which is at the top of this form , onto the computer , to go along with the where the digits are recorded automatically . grad f: And so it 's just , you know , typing in name , times time , date , and so on .  , which again either they can do , but it is , you know , firing up an editor , or , again , I can do . postdoc b: And , that , you know , I 'm not , that that one I 'm not so sure if it 's into the the , things that , I , wanted to use the hours for , because the , the time that they 'd be spending doing that they wouldn't be able to be putting more words on . postdoc b: But that 's really your choice , it 's your phd d: So are these two separate tasks that can happen ? Or do they have to happen at the same time before grad f: No they don't have this you have to enter the data before , you do the second task , but they don't have to happen at the same time . grad f: So it 's it 's just I have a file whi which has this information on it , and then when you start using my scripts , for extracting the times , it adds the times at the bottom of the file . And so , it 's easy to create the files and leave them blank , and so actually we could do it in either order . grad f: it 's it 's sort of nice to have the same person do it just as a double - check , to make sure you 're entering for the right person . Yeah just by way of  , a  , order of magnitude , we 've been working with this Aurora ,  data set . And , the best score , on the , nicest part of the data , that is , where you 've got training and test set that are basically the same kinds of noise and so forth , is about ,  I think the best score was something like five percent , error , per digit . So So the The point there , and this is  car noise  ,  things , but but real real situation , phd d:   professor c: well , " real " , the  there 's one microphone that 's close , that they have as as this sort of thing , close versus distant .  but in a car , instead of instead of having a projector noise it 's it 's car noise . So , that 's that 's an indication ,  that was with , many sites competing , and this was the very best score and so forth , so . More typical numbers like phd d: Although the models weren't , that good , right ?  , the models are pretty crappy ? professor c: You 're right . I think that we could have done better on the models , but the thing is that we got this this is the kind of typical number , for all of the , things in this task , all of the , languages . Anyway , just an indication once you get into this kind of realm even if you 're looking at connected digits it can be pretty hard . phd d: How did we do on the TI - digits ? grad f: Well the prosodics are so much different s it 's gonna be , strange . grad f: So I 'm I 'm not sure how much of effect that will have . phd d: H how do phd g: What do you mean , the prosodics ? grad f: just what we were talking about with grouping . That with these , the grouping , there 's no grouping at all , and so it 's just the only sort of discontinuity you have is at the beginning and the end . phd g: So what are they doing in Aurora , are they reading actual phone numbers , grad f: Aurora I don't know . phd g: or , a a digit at a time , or ? professor c: I 'm not sure how phd g: Cuz it 's professor c: no , no  it 's connected it 's connected , digits , phd g: Connected . phd g: So there 's also the not just the prosody but the cross the cross - word modeling is probably quite different . phd d: H How grad f: But in TI - digits , they 're reading things like zip codes and phone numbers and things like that , phd g: Right . phd d: do we do on TI - digits ? grad f: so it 's gonna be different . grad f: One and a half percent , two percent , something like that ? professor c: I th no I think we got under a percent , but it was but it 's but  . The very best system that I saw in the literature was a point two five percent or something that somebody had at at Bell Labs , or . It s strikes me that there are more each of them is more informative because it 's so , random , grad f: OK . professor c: But I think a lot of systems sort of get half a percent , or three - quarters a percent , grad f: Right . grad f: But that  it 's really it 's it 's close - talking mikes , no noise , clean signal , just digits , every everything is good . phd g: It 's like the , single cell , you know , it 's the beginning of life , phd d: Pre - prehistory . grad f: OK , so , what I 'll do then is I 'll go ahead and enter , this data . And then , hand off to Jane , and the transcribers to do the actual extraction of the digits . One question I have that that  , we wouldn't know the answer to now but might , do some guessing , but I was talking before about doing some model modeling of arti  , marking of articulatory , features , with overlap and so on . The only thing is I 'm a little concerned that maybe the kind of phenomena , in w i i The reason for doing it is because the the argument is that certainly with conversational speech , the stuff that we 've looked at here before , just doing the simple mapping , from , the phone , to the corresponding features that you could look up in a book , isn't right . In fact there 's these overlapping processes where some voicing some up and then some , you know , some nasality is comes in here , and so forth . But , It could be that when we 're reading digits , because it 's it 's for such a limited set , that maybe maybe that phenomenon doesn't occur as much . Di - an anybody ? Do you have any ? Anybody have any opinion about that , postdoc b: and that people might articulate more , and you that might end up with more a closer correspondence . phd d: Sort of less predictability , grad f: That it 's just postdoc b:   phd d: and You hafta grad f: It 's a Well Would , this corpus really be the right one to even try that on ? phd g: Well it 's definitely true that , when people are , reading , even if they 're re - reading what , they had said spontaneously , that they have very different patterns . phd g: So the fact that they 're reading , first of all , whether they 're reading in a room of , people , or rea you know , just the fact that they 're reading will make a difference . So , may maybe the thing will be do to take some very small subset ,  not have a big , program , but take a small set , subset of the conversational speech and a small subset of the digits , and look and and just get a feeling for it . postdoc b: H That could could be an interesting design , too , cuz then you 'd have the com the comparison of the , predictable speech versus the less predictable speech professor c: Cuz I don't think anybody is , I at least , I don't know , of anybody , well , I don't know , the answers . postdoc b: and maybe you 'd find that it worked in , in the , case of the pr of the , non - predictable . phd d: Hafta think about , the particular acoustic features to mark , too , because , some things , they wouldn't be able to mark , like , you know , tense lax . grad f: M I think we can get Ohala in to , give us some advice on that . postdoc b: Also I thought you were thinking of a much more restricted set of features , that professor c: Yeah , but I I I I was , like he said , I was gonna bring John in and ask John what he thought . It should be such that if you , if you , if you had o  , all of the features , determined that you that you were  ch have chosen , that that would tell you , in the steady - state case , the phone . grad f: Even , I guess with vowels that would be pretty hard , wouldn't it ? To identify actually , you know , which one it is ? postdoc b: It would seem to me that the points of articulation would be m more , g  ,  that 's I think about articulatory features , I think about , points of articulation , which means , rather than vowels . phd d: Points of articulation ? What do you mean ? postdoc b: So , is it , bilabial or dental or is it , you know , palatal . phd g: Well it 's also , there 's , really a difference between , the pronunciation models in the dictionary , and , the pronunciations that people produce . And , so , You get , some of that information from Steve 's work on the on the labeling professor c: Right . That maybe , although I think the meeting context is great , that he has transcriptions that give you the actual phone sequence . And you can go from not from that to the articulatory features , but that would be a better starting point for marking , the gestural features , then , data where you don't have that , because , we you wanna know , both about the way that they 're producing a certain sound , and what kinds of , you know what kinds of , phonemic , differences you get between these , transcribed , sequences and the dictionary ones . professor c: Well you might be right that mi might be the way at getting at , what I was talking about , but the particular reason why I was interested in doing that was because I remember , when that happened , and , John Ohala was over here and he was looking at the spectrograms of the more difficult ones . One you know , one is going from a dictionary pronunciation of something , like , " gonna see you tomorrow " , grad f: And Or " gonta " . phd g: it could be " going to " or " gonna " or " gonta s " you know . And , that it would be nice to have these , intermediate , or these some these reduced pronunciations that those transcribers had marked or to have people mark those as well . phd g: Because , it 's not , that easy to go from the , dictionary , word pronuncia the dictionary phone pronunciation , to the gestural one without this intermediate or a syllable level kind of , representation . grad f: Well I don't think Morgan 's suggesting that we do that , though . professor c: Yeah , I I I 'm jus at the moment of course we 're just talking about what , to provide as a tool for people to do research who have different ideas about how to do it . So for instance , you might have someone who just has a wor has words with states , and has   , comes from articulatory gestures to that . But  , grad f: But What I 'm imagining is a score - like notation , where each line is a particular feature . grad f: so you would say , you know , it 's voiced through here , and so you have label here , and you have nas nasal here , and , they they could be overlapping in all sorts of bizarre ways that don't correspond to the timing on phones . professor c:  this is the kind of reason why I remember when at one of the Switchboard , workshops , that  when we talked about doing the transcription project , Dave Talkin said , " can't be done " . professor c: He was he was , what what he meant was that this isn't , you know , a sequence of phones , and when you actually look at Switchboard that 's , not what you see , and , you know . It , grad f: And in in fact the inter - annotator agreement was not that good , right ? On the harder ones ? professor c: yeah  it was phd g: It depends how you look at it , and I I understand what you 're saying about this , kind of transcription exactly , professor c: Yeah . phd g: because I 've seen you know , where does the voicing bar start and so forth . phd g: All I 'm saying is that , it is useful to have that the transcription of what was really said , and which syllables were reduced .  , if you 're gonna add the features it 's also useful to have some level of representation which is , is a reduced it 's a pronunciation variant , that currently the dictionaries don't give you professor c:   phd g: because if you add them to the dictionary and you run recognition , you , you add confusion . phd d: So it would be it would be great if we had , either these kind of , labelings on , the same portion of Switchboard that Steve marked , or , Steve 's type markings on this data , with these . phd g: And Steve 's type is fairly it 's not that slow , I dunno exactly what the , timing was , but . professor c: Yeah u I don't disagree with it the on the only thing is that , What you actually will end en end up with is something , i it 's all compromised , right , so , the string that you end up with isn't , actually , what happened . But it 's it 's the best compromise that a group of people scratching their heads could come up with to describe what happened . And it 's more accurate than the than the dictionary or , if you 've got a pronunciation  lexicon that has three or four , grad f: The word . professor c: this might be have been the fifth one that you tr that you pruned or whatever , phd d: So it 's like a continuum . phd g: an and in some places it would fill in , So the kinds of gestural features are not everywhere . phd g: So there are some things that you don't have access to either from your ear or the spectrogram , phd d:   phd g: but you know what phone it was and that 's about all you can all you can say . phd g: And then there are other cases where , nasality , voicing phd d: It 's basically just having , multiple levels of of , information and marking , on the signal . grad f: Well the other difference is that the the features , are not synchronous , phd g: Right . phd g: Th - there 'll be no way for you to actually mark what was said completely by features . grad f: Well not with our current system but you could imagine designing a system , that the states were features , rather than phones . phd g: And i if you 're Well , we we 've probably have a separate , discussion of ,  of whether you can do that . postdoc b: That 's Well , isn't that I thought that was , well but that wasn't that kinda the direction ? grad f: Yeah . postdoc b: I thought professor c: Yeah , so  , what , what where this is , I I want would like to have something that 's useful to people other than those who are doing the specific kind of research I have in mind , so it should be something broader . But , The but  where I 'm coming from is , we 're coming off of stuff that Larry Saul did with with , John Dalan and Muzim Rahim in which , they , have , a m a multi - band system that is , trained through a combination of gradient learning an and EM , to  , estimate , the , value for m for for a particular feature . And this is part of a larger , image that John Dalan has about how the human brain does it in which he 's sort of imagining that , individual frequency channels are coming up with their own estimate , of of these , these kinds of something like this . And the the th this particular image , of how thi how it 's done , is that , then given all of these estimates at that level , there 's a level above it , then which is is making , some kind of sound unit classification such as , you know , phone and and , you know . But that that 's sort of what I was imagining doing , and but it 's still open within that whether you would have an intermediate level in which it was actually phones , or not .  , but , Again , I wouldn't wanna , wouldn't want what we we produced to be so , know , local in perspective that it it was matched , what we were thinking of doing one week , And and , and , you know , what you 're saying is absolutely right . That , that if we , can we should put in , another level of , of description there if we 're gonna get into some of this low - level stuff . phd d: Well , you know ,   if we 're talking about , having the , annotators annotate these kinds of features , it seems like , You know , you The the question is , do they do that on , meeting data ? Or do they do that on , Switchboard ? grad f: That 's what I was saying , postdoc b: W Well it seems like you could do both . postdoc b: I was thinking that it would be interesting , to do it with respect to , parts of Switchboard anyway , in terms of , professor c:   postdoc b:  partly to see , if you could , generate first guesses at what the articulatory feature would be , based on the phone representation at that lower level . phd d: Well cuz the yeah , and then also , if you did it on Switchboard , you would have , the full continuum of transcriptions . phd d: You 'd have it , from the lowest level , the ac acoustic features , then you 'd have the , you know , the phonetic level that Steve did , postdoc b:   phd g: it is telephone band , so , the bandwidth might be phd d: It 'd be a complete , set then . So  i we 'll see wha how much we can , get the people to do , and how much money we 'll have and all this sort of thing , phd g: Yeah . phd d: But it it might be good to do what Jane was saying  , you know , seed it , with , guesses about what we think the features are , based on , you know , the phone or Steve 's transcriptions or something . grad f: Alright , so based on the phone transcripts they would all be synchronous , but then you could imagine , nudging them here and there . professor c: Well I think what  I 'm I 'm a l little behind in what they 're doing , now , and , the stuff they 're doing on Switchboard now . But I think that , Steve and the gang are doing , something with an automatic system first and then doing some adjustment . So  that 's probably the right way to go anyway , is to is to start off with an automatic system with a pretty rich pronunciation dictionary that , that , you know , tries , to label it all . postdoc b: So in in our case you 'd think about us s starting with maybe the regular dictionary entry , and then ? Or would we professor c: Well , regular dictionary , this is a pretty rich dictionary . It 's got , got a fair number of pronunciations in it postdoc b: But phd d: Or you could start from the if we were gonna , do the same set , of sentences that Steve had , done , we could start with those transcriptions . phd g: the problem is when you run , if you run a regular dictionary , even if you have variants , in there , which most people don't , you don't always get , out , the actual pronunciations , phd d: Yeah . phd g: so that 's why the human transcriber 's giving you the that pronunciation , postdoc b: Yeah . phd g: and so y they they I thought that they were professor c: Is that what they 're doing ? grad f: They are . professor c: Yeah , so I think that i i we also don't have , we 've got a good start on it , but we don't have a really good , meeting , recorder or recognizer or transcriber or anything yet , so . So ,  another way to look at this is to , is to , do some stuff on Switchboard which has all this other , stuff to it . professor c: And then , As we get , further down the road and we can do more things ahead of time , we can , do some of the same things to the meeting data . postdoc b: And I 'm and these people might they they are , s most of them are trained with IPA . professor c: Yeah postdoc b: They 'd be able to do phonetic - level coding , or articulatory . phd d: Are they busy for the next couple years , or ? postdoc b: Well , you know ,  they , they they 're interested in continuing working with us , so  I , and this would be up their alley , so , we could when the when you d meet with , with John Ohala and find , you know what taxonomy you want to apply , then , they 'd be , good to train onto it . phd g: It might be grad f:  you 'd you 'd want models for spreading . phd g: I was thinking it might be n phd d: Of the f acoustic features ? grad f: Yeah . phd g: Well it might be neat to do some , phonetic , features on these , nonword words . Are are these kinds of words that people never the " huh "s and the "  "s and the " huh " and the  These k No , I 'm serious . phd g: And some of them are , yeah , "  - huh "s , and "  "s , and , "  ! " "  " " OK " , "  " Grunts , that might be interesting . professor c: new version of , presegmentation ? phd a: oh yeah , I worked a little bit on the on the presegmentation to to get another version which does channel - specific , speech - nonspeech detection . And , what I did is I used some normalized features which , look in into the which is normalized energy , energy normalized by the mean over the channels and by the , minimum over the , other . And to to , to , yeah , to normalize also loudness and and modified loudness and things and that those special features actually are in my feature vector . phd a: And , and , therefore to be able to , somewhat distinguish between foreground and background speech in in the different in each channel . And , eh , I tested it on on three or four meetings and it seems to work , well yeah , fairly well , I I would say . grad f: So I I understand that 's what you were saying about your problem with , minimum . phd a: Yeah yeah , then I I did some some some things like that , postdoc b: Interesting . phd a: as there there are some some problems in , when , in the channel , there they the the speaker doesn't doesn't talk much or doesn't talk at all . Then , the , yeah , there are there are some problems with with with n with normalization , and , then , there the system doesn't work at all . So , I 'm I 'm glad that there is the the digit part , where everybody is forced to say something , professor c: Right . And , the thing is I I , then the evaluation of of the system is a little bit hard , as I don't have any references . phd a: Yeah , that 's the one one wh where I do the training on so I can't do the evaluation on So the thing is , can the transcribers perhaps do some , some some meetings in in terms of speech - nonspeech in in the specific channels ? grad f:  . postdoc b: Well , I have phd d: Well won't you have that from their transcriptions ? postdoc b: Well , OK , so , now we need grad f: No , cuz we need is really tight . postdoc b: so , I think I might have done what you 're requesting , though I did it in the service of a different thing . postdoc b: I have thirty minutes that I 've more tightly transcribed with reference to individual channels . postdoc b: And I could And And grad f: Hopefully that 's not the same meeting that we did . postdoc b: So , e so the , you know , we have the , th they transcribe as if it 's one channel with these with the slashes to separate the overlapping parts . postdoc b: And then we run it through then it then I 'm gonna edit it and I 'm gonna run it through channelize which takes it into Dave Gelbart 's form format . postdoc b: And then you have , all these things split across according to channel , and then that means that , if a person contributed more than once in a given , overlap during that time bend that that two parts of the utterance end up together , it 's the same channel , phd a: OK . postdoc b: and then I took his tool , and last night for the first thirty minutes of one of these transcripts , I , tightened up the , boundaries on individual speakers ' channels , phd a: OK . postdoc b: cuz his his interface allows me to have total flexibility in the time tags across the channels . phd a: so , yeah yeah , that that that 's great , but what would be nice to have some more meetings , not just one meeting to to be sure that that , there is a system , phd d: So , current This week . grad f: Yeah , so if we could get a couple meetings done with that level of precision I think that would be a good idea .  , how how m much time so the meetings vary in length , what are we talking about in terms of the number of minutes you 'd like to have as your as your training set ? phd a: It seems to me that it would be good to have , a few minutes from from different meetings , so . postdoc b: OK , now you 're saying different meetings because of different speakers or because of different audio quality or both or ? phd a: Both both . professor c: Yeah , we don't have that much variety in meetings yet ,  we have this meeting and the feature meeting and we have a couple others that we have  , couple examples of . grad e: Even probably with the gains differently will affect it , you mean phd a: not really as professor c: Poten - potentially . phd g: We can try running we haven't done this yet because , Andreas an is is gonna move over the SRI recognizer . phd g: cuz we 're running the evals and I just don't have machine time there . But , once that 's moved over , hopefully in a a couple days , then , we can take , what Jane just told us about as , the presegmented , the the segmentations that you did , at level eight or som at some , threshold that Jane , tha right , and try doing , forced alignment . phd g: And if it 's good , then that will that may give you a good boundary . Of course if it 's good , we don't then we 're we 're fine , phd a: Yeah . M phd g: but , I don't know yet whether these , segments that contain a lot of pauses around the words , will work or not . phd a: I I would quite like to have some manually transcribed references for for the system , as I 'm not sure if if it 's really good to compare with with some other automatic , found boundaries . postdoc b: Well , no , if we were to start with this and then tweak it h manually , would that that would be OK ? phd a: Yeah . phd g: but , I would have maybe a transciber , look at the result of a forced alignment and then adjust those . phd g: If they 're horrible it won't help at all , but they might not be horrible . postdoc b: How many minutes would you want from  , we could easily , get a section , you know , like say a minute or so , from every meeting that we have so f from the newer ones that we 're working on , everyone that we have . phd a: If it 's not the first minute of of the meeting , that that 's OK with me , but , in in the first minute , Often there are some some strange things going on which which aren't really , well , for , which which aren't re re really good . What what I 'd quite like , perhaps , is , to have , some five minutes of of of different meetings , so . postdoc b: And , then I wanted to ask you just for my inter information , then , would you , be trai cuz I don't quite unders so , would you be training then , the segmenter so that , it could , on the basis of that , segment the rest of the meeting ? So , if I give you like five minutes is the idea that this would then be applied to , to , providing tighter time bands ? phd a: I I could do a a retraining with that , yeah . phd a: That 's but but I hope that I I don't need to do it . phd a: I 'm I 'm not sure , but , for for for those three meetings whi which I which I did , it seems to be , quite well , but , there are some some as I said some problems with the lapel mike , but , perhaps we can do something with with cross - correlations to , to get rid of the of those . Well well what I want to do is to to look into cross - correlations for for removing those , false overlaps . phd g: Are the , wireless , different than the wired , mikes , at all ?  , have you noticed any difference ? phd a: I 'm I 'm not sure , if if there are any wired mikes in those meetings , or , I have have to loo have a look at them but , I 'm I 'm I think there 's no difference between , phd g: So it 's just the lapel versus everything else ? phd a: Yeah . postdoc b: OK , so then , if that 's five minutes per meeting we 've got like twelve minutes , twelve meetings , roughly , that I 'm that I 've been working with , then professor c: Of of of the meetings that you 're working with , how many of them are different , tha phd a: No . professor c: are there any of them that are different than , these two meetings ? postdoc b: Well oh wa in terms of the speakers or the conditions or the ? professor c: Yeah , speakers . postdoc b: just from what I 've seen , there are some where , you 're present or not present , and , then then you have the difference between the networks group and this group phd a: Yeah , I know , some of the NSA meetings , yeah . professor c: Do you have any of Jerry 's meetings in your , pack , er , postdoc b: no . professor c: No ? postdoc b: We could ,  you you recorded one last week or so . professor c: and and having as much variety for speaker certainly would be a big part of that I think . postdoc b: OK , so if I , OK , included include , OK , then , if I were to include all together samples from twelve meetings that would only take an hour and I could get the transcribers to do that right  , what  is , that would be an hour sampled , and then they 'd transcribe those that hour , right ? That 's what I should do ? professor c: Yeah . So they get it into the multi - channel format and then adjust the timebands so it 's precise . professor c: So that should be faster than the ten times kind of thing , postdoc b: Absolutely . postdoc b: Oh gosh , well , last night , I did about half an hour in , three hours , which is not , terrific , professor c: Yeah . postdoc b: but , anyway , it 's an hour and a half per professor c: Yeah . phd a: Do the transcribers actually start wi with , transcribing new meetings , or are they ? postdoc b: Well ,  they 're still working they still have enough to finish that I haven't assigned a new meeting , phd a: OK . postdoc b: but the next , m m I was about to need to assign a new meeting and I was going to take it from one of the new ones , phd a: OK . phd g: So they 're really running out of , data , prett  that 's good . professor c: They 're running out of data unless we s make the decision that we should go over and start , transcribing the other set . postdoc b: And so I was in the process of like editing them but this is wonderful news . postdoc b: We funded the experiment with ,  also we were thinking maybe applying that that to getting the , Yeah , that 'll be , very useful to getting the overlaps to be more precise all the way through . So , Liz , and and Don , and I met this morning , in the BARCO room , with the lecture hall , professor c: OK . postdoc b: and this afternoon , it drifted into the afternoon , concerning this issue of , the , well there 's basically the issue of the interplay between the transcript format and the processing that , they need to do for , the SRI recognizer . And , well , so , I mentioned the process that I 'm going through with the data , so , you know , I get the data back from the transcri Well , s  , metaphorically , get the data back from the transcriber , and then I , check for simple things like spelling errors and things like that . And , I 'm going to be doing a more thorough editing , with respect to consistency of the conventions . And , then , I run it through , the channelize program to get it into the multi - channel format , OK . And the , what we discussed this morning , I would summarize as saying that , these units that result , in a a particular channel and a particular timeband , at at that level , vary in length . But it 's really an empirical question , whether the units we get at this point through , just that process I described might be sufficient for them . So , as a first pass through , a first chance without having to do a lot of hand - editing , what we 're gonna do , is , I 'll run it through channelize , give them those data after I 've done the editing process and be sure it 's clean . And I can do that , pretty quickly , with just , that minimal editing , without having to hand - break things . postdoc b: And then we 'll see if the units that we 're getting , with the at that level , are sufficient . And if they do need to be further broken down then maybe it just be piece - wise , maybe it won't be the whole thing . So , that 's that 's what we were discussing , this morning as far as I Among phd g: Right . postdoc b: also we discussed some adaptational things , phd g: Then lots of postdoc b: so it 's like , phd g: Right . postdoc b:  You know I hadn't , incorporated , a convention explicitly to handle acronyms , for example , but if someone says , PZM it would be nice to have that be directly interpretable from , the transcript what they said , professor c:   It 's like y it 's and so , I 've I 've incorporated also convention , with that but that 's easy to handle at the post editing phase , and I 'll mention it to , transcribers for the next phase but that 's OK .  , and also I 'll be , encoding , as I do my post - editing , the , things that are in curly brackets , which are clarificational material . So , it 's gonna be either a gloss or it 's gonna be a vocal sound like a , laugh or a cough , or , so forth . Or a non - vocal sound like a doors door - slam , and that can be easily done with a , you know , just a one little additional thing in the , in the general format . phd g: Yeah we j we just needed a way to , strip , you know , all the comments , all the things th the that linguist wants but the recognizer can't do anything with .  , but to keep things that we mapped to like reject models , or , you know , mouth noise , or , cough . And then there 's this interesting issue Jane brought up which I hadn't thought about before but I was , realizing as I went through the transcripts , that there are some noises like , well the good example was an inbreath , where a transcriber working from , the mixed , signal , doesn't know whose breath it is , grad f: Right . phd g: and they 've been assigning it to someone that may or may not be correct . And what we do is , if it 's a breath sound , you know , a sound from the speaker , we map it , to , a noise model , like a mouth - noise model in the recognizer , and , yeah , it probably doesn't hurt that much once in a while to have these , but , if they 're in the wrong channel , that 's , not a good idea . And then there 's also , things like door - slams that 's really in no one 's channel , they 're like it 's in the room . phd g: And  , Jane had this nice , idea of having , like an extra ,  couple tiers , grad f: An extra channel . So if they hear a breath and they don't know who breath it is it 's better to put it in that channel than to put it in the speaker 's channel because maybe it was someone else 's breath , or  , so I think that 's a good you can always clean that up , post - processing . phd g: So a lot of little details , but I think we 're , coming to some kinda closure , on that . So the idea is then , Don can take , Jane 's post - processed channelized version , and , with some scripts , you know , convert that to to a reference for the recognizer and we can , can run these . So when that 's , ready you know , as soon as that 's ready , and as soon as the recognizer is here we can get , twelve hours of force - aligned and recognized data . And , you know , start , working on it , postdoc b: And phd g: so we 're , I dunno a coup a week or two away I would say from , if if that process is automatic once we get your post - process , transcript . I 'm just hoping that the units that are provided in that way , will be sufficient cuz I would save a lot of , time , dividing things . Just from I dunno how long were you did one ? grad e: I saw a couple , around twenty seconds , and that was just without looking too hard for it , so , I would imagine that there might be some that are longer . postdoc b: Well n One question , e w would that be a single speaker or is that multiple speakers overlapping ? grad e: No . No , but if we 're gonna segment it , like if there 's one speaker in there , that says " OK " or something , right in the middle , it 's gonna have a lot of dead time around it , phd g: Right . It 's not the it 's not the fact that we can't process a twenty second segment , it 's the fact that , there 's twenty seconds in which to place one word in the wrong place grad e: so it 's not postdoc b: Yeah . phd g: You know , if if someone has a very short utterance there , and that 's where , we , might wanna have this individual , you know , ha have your pre pre - process input . phd a: I I I thought that perhaps the transcribers could start then from the those mult multi - channel , speech - nonspeech detections , if they would like to . phd g: So that 's probably what will happen , but we 'll try it this way and see . We 'll probably get lots of errors because of the cross - talk , and , noises and things . postdoc b: Oh I wanted to ask one thing , the microphones the new microphones , professor c: Yeah ? K . postdoc b: when do we get ,  ? grad f: they said it would take about a week . phd g: So what happens to our old microphones ? professor c: They go where old microphones go . grad f:  phd g: Do we give them to someone , or ? grad f: Well the only thing we 're gonna have extra , for now , phd g: We don't have more receivers , we just have grad f: Right , we don so the only thing we 'll have extra now is just the lapel . Since , what I decided to do , on Morgan 's suggestion , was just get two , new microphones , and try them out . grad f: Since they 're they 're like two hundred bucks a piece , we won't , at least try them out . phd d: So it 's a replacement for this headset mike ? grad f: Yep . phd d: What 's the , style of the headset ? grad f: It 's , it 's by Crown , and it 's one of these sort of mount around the ear thingies , and , when I s when I mentioned that we thought it was uncomfortable he said it was a common problem with the Sony . grad f: And I checked on the web , and every site I went to , raved about this particular mike . It 's apparently comfortable and stays on the head well , so we 'll see if it 's any good . postdoc b: You said it was used by aerobics instructors ? grad f:  Yep . professor c: For the recor for the record Adam is not a paid employee or a consultant of Crown . professor c: I said " For the record Adam is is not a paid consultant or employee of Crown " . grad f: The P Z Ms are Crown , aren't they ? professor c: Yeah . professor c: So if we go to a workshop about all this this it 's gonna be a meeting about meetings about meetings . professor c: Oh , yeah , what Which 'll be the meeting about the meeting about the meeting . grad f: Cuz then it would be a meeting about the meeting about the meeting about meetings . phd a: S s grad f: Pause between the lines , remember ? grad e: Excuse me 