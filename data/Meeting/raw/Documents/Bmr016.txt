grad d: and  pick out the ones that have problems , and either correct them or have them re - read . So we probably have like four or five more forms to be read , to be once through the set . I extracted out about an hour 's worth which are the f digits with for which whose speaker have speaker forms , have filled out speaker forms . So I extracted one for speakers who have speaker forms and for meetings in which the " key " file and the transcript files are parsable . Some of the early key files , it looks like , were done by hand , and so they 're not automatically parsable and I have to go back and fix those .  , Liz professor f: So you think two you think two hours is the is the total that we have ? grad d: Yep , yeah . professor f: And you think we th  , I I didn't quite catch all these different things that are not quite right , but you think we 'll be able to retrieve the other hour , reasonably ? grad d: Yes , absolutely . grad d: So it 's just a question of a little hand - editing of some files and then waiting for more people to turn in their speaker forms . I have this web - based speaker form , and I sent mail to everyone who hadn't filled out a speaker form , and they 're slowly s trickling in . professor f: So the relevance of the speaker form here , s grad d: It 's for labeling the extracted audio files . grad d: No , I spoke with Jane about that and we sort of decided that it 's probably not an issue that We edit out any of the errors anyway . So the other topic with digits is  , Liz would like to elicit different prosodics , and so we tried last week with them written out in English . So in conversations with Liz and  Jane we decided that if you wrote them out as numbers instead of words it would elicit more phone number , social security number - like readings . When I look at this , that first line is " sixty one , sixty two , eighteen , eighty six , ten . "  , and so the question is does anyone care ?  , I 've already spoken with Liz and she feels that , correct me if I 'm wrong , that for her , connected numbers is fine , postdoc e: I think two hours is probably fine for a test set , but it may be a little short if we actually wanna do training and adaptation and all that other stuff . professor f: Yeah  , do  you want different prosodics , so if you always had the same groupings you wouldn't like that ? Is that correct ? phd g: Well , we actually figured out a way to grad d: Yeah , the the phd g: the the groupings are randomly generated . professor f: No but , I was asking if that was something you really cared about because if it wasn't , it seems to me if you made it really specifically telephone groupings that maybe people wouldn't , go and do numbers so much . You know if it if it 's phd a:  phd g: I think they may still do it , professor f: Maybe some , but I probably not so much . phd b: What about putting a hyphen between the numbers in the group ? phd g: And professor f: Right ? So if you if if you have  grad d: Six dash one , you mean ? professor f: if you go six six six  dash  two nine three one . phd g: I well OK I it might help , I would like to g get away from having only one specific grouping . phd g: but  it seems to me that , at least for us , we can learn to read them as digits postdoc e: Yeah . phd g: and it seems like that might be better for you guys since then you 'll have just more digit data , grad d: Right . phd g: It 's a little bit better for me too because the digits are easier to recognize . Right , read them as single digits , so sixty - one w is read as six one , postdoc e:   phd g: and if people make a mistake we grad d: How about " O " versus " zero " ? professor f: the other thing is we could just bag it because it 's it 's it 's - I 'm not worrying about it  , because we do have digits training data that we have from  from OGI . I 'm sorry , digits numbers training that we have from OGI , we 've done lots and lots of studies with that . phd g: But it 's nice to get it in this room with the acous professor f: Yeah . phd g:  for it 's professor f: No , no , I guess what I 'm saying is that grad d: Just let them read it how they read it . professor f: to some extent maybe we could just read them have them read how how they read it and it just means that we have to expand our our vocabulary out to stuff that we already have . Well that 's fine with me as long as It 's just that I didn't want to cause the people who would have been collecting digits the other way to not have the digits . phd g: So professor f:  we s we we 've We can do this for awhile phd g: OK . Do yo  , do you want do you want this Do you need training data or adaptation data out of this ? phd g: OK . professor f: How much of this do you need ? with  the phd g: It 's actually unclear right now . I just thought well we 're if we 're collec collecting digits , and Adam had said we were running out of the TI forms , I thought it 'd be nice to have them in groups , and probably , all else being equal , it 'd be better for me to just have single digits professor f: OK . phd g: since it 's , you know , a recognizer 's gonna do better on those anyway , and it 's more predictable . So we can know from the transcript what the person said and the transcriber , in general . professor f: OK , well if you pre phd g: But if they make mistakes , it 's no big deal if the people say a hundred instead of " one OO " . and also w maybe we can just let them choose " zero " versus " O " as they as they like because even the same person c sometimes says " O " and sometimes says " zero " in different context , professor f: Yeah . So I don't have a Specific need cuz if I did I 'd probably try to collect it , you know , without bothering this group , but If we can try it grad d: OK so so I can just add to the instructions to read it as digits not as connected numbers . phd g: Right , and you can give an example like , you know , " six sixty - one would be read as six one " . And is the spacing alright or do you think there should be more space between digits and groups ? professor f: OK . phd g: and grad d: Or is that alright ? phd g:  what do other people think cuz you guys are reading them . postdoc e: I it it to me it looks like you 've got the func the idea of grouping and you have the grou the idea of separation phd g: OK . postdoc e: and , you know , it 's just a matter of u i the instructions , that 's all . grad d: And I think there are about ten different gouping patterns professor f: Let 's try it . phd g: Righ - right , and you just they 're randomly generated and randomly assigned to digits . professor f: Sorry , I I was just gonna say , so we have in the vicinity of forty hours of of recordings now . And you 're saying two hours , is digits , so that 's roughly the ratio then , grad d: Yep . professor f: yeah like you say , I think a couple hours for a for a for a test test set 's OK . It 'd be nice to get , you know , more later because we 'll we might use use this up , in some sense , postdoc e:   professor f: but but  postdoc e: Yeah , I also would like to argue for that cuz it it seems to me that , there 's a real strength in having the same test replicated in a whole bunch of times and adding to that basic test bank . postdoc e:  ? Cuz then you have , you know , more and more , u chances to get away from random errors . And I think , the other thing too is that right now we have sort of a stratified sample with reference to dialect groups , and it might be there might be an argument to be made for having  f for replicating all of the digits that we 've done , which were done by non - native speakers so that we have a core that totally replicates the original data set , which is totally American speakers , and then we have these stratified additional language groups overlapping certain aspects of the database . I think that  trying to duplicate , spending too much effort trying to duplicate the existing TI - digits probably isn't too worthwhile because the recording situation is so different . postdoc e: Except that if you have the stimuli comparable , then it says something about the the contribution of setting professor f: No it 's it 's not the same . postdoc e: and professor f: A little bit , but the other differences are so major . professor f: They 're such major sources of variance that it 's it 's it 's  postdoc e: What 's an example of a of m some of the other differences ? Any other a difference ? professor f: Well i i individual human glottis is going to be different for each one , postdoc e: OK .  , we 're collecting it in a read digit in a particular list , and I 'm sure that they 're doing more specific stuff . grad d: Was it read ? professor f: Yeah , I think the reading zipcode stuff you 're thinking of would be OGI . professor f: Yeah , no TI - digits was read in th in read in the studio I believe . grad d: But but regardless it 's gonna it 's hard to compare cross - corpus . professor f: And they 're different circumstances with different recording environment and so forth , so it 's it 's it 's really pretty different . But I think the idea of using a set thing was just to give you some sort of framework , so that even though you couldn't do exact comparisons , it wouldn't be s valid scientifically at least it 'd give you some kind of  frame of reference .  , you know it 's not phd b: Hey Liz , What what do the groupings represent ? postdoc e: OK . phd b: You said there 's like ten different groupings ? phd g: Right , just groupings in terms of number of groups in a line , and number of digits in a group , and the pattern of groupings . Are the patterns like are they based on anything or phd g: I I just roughly looked at what kinds of digit strings are out there , and they 're usually grouped into either two , three , or four , four digits at a time . In the old days you probably only had three sequences , and telephone numbers were less , and so forth . So , there 's between ,  Well if you look at it , there are between like three and five groups , and each one has between two and four groupings and I purposely didn't want them to look like they were in any kind of pattern . phd g: So grad d: And which group appears is picked randomly , and what the numbers are are picked randomly . grad d: So unlike the previous one , which I d simply replicated TI - digits , this is generated randomly . phd g: But I think it 'd be great i to be able to compare digits , whether it 's these digits or TI - digits , to speakers , and compare that to their spontaneous speech , and then we do need you know a fair amount of of digit data because you might be wearing a different microphone grad d:   phd g: and ,  so it 's it 's nice to have the digits you know , replicated many times . phd g: so we have a problem with acoustic adaptation , and we 're not using the digit data now , but you know grad d: Oh , you 're not . v W we 're not we were running adaptation only on the data that we ran recognition on and I 'd As soon as someone started to read transcript number , that 's read speech and I thought " well , we 're gonna do better on that , grad d: Oh I see . So those speakers who are very quiet , shy grad d: That would be interesting to see whether that helps . phd g: r Right phd b: Like Adam ? grad d: Do you think that would help adapting on Yeah . phd g: Well , it sh  it 's the same micropho see the nice thing is we have that in the in the same meeting , grad d: Right . phd g: and so you don't get grad d: same microphone , phd a: Yeah . professor f: Yeah  , for the for the  acoustic research , for the signal - processing , farfield stuff , I see it as as as the place that we start . But , th  , it 'd be nice to have twenty hours of digits data , but but  the truth is I 'm hoping that we we through the the stuff that that you guys have been doing as you continue that , we get , the best we can do on the spontaneous stuff  ,  nearfield , and then  , we do a lot of the testing of the algorithms on the digits for the farfield , and at some point when we feel it 's mature and we understand what 's going on with it then we we have to move on to the spontaneous data with the farfield . phd g: The only thing that we don't have , I know this sounds weird , and maybe it 's completely stupid , but we don't have any overlapping digits . phd g: An - yea I know it 's weird , but  phd a: Overlapping digits ! grad d: The the problem I see with trying to do overlapping digits is the cognitive load . grad d: No it 's it 's not stupid , it 's just  , try to do it . phd g: I 'm just talkin for the stuff that like Dan Ellis is gonna try , grad d: here , let 's try it . phd g: OK So but grad d: So so you read the last line , I 'll read the first line . professor f: No , I 'll p phd g: So you plu you plug your ears . grad d: Oh I guess if you plug you 're ears you could do it , but then you don't get the the same effects . phd g: Well , what  is actually no not the overlaps that are well - governed linguistically , but the actual fact that there is speech coming from two people grad d: Yeah . phd g: and the beam - forming stuf all the acoustic stuff that like Dan Ellis and and company want to do . phd g: It would take one around amount of ti phd b: It 's the P - make of digit reading . I I mea I 'm I was sort of serious , but I really , I 'm I don't feel strongly enough that it 's a good idea , professor f: See , y grad d: You do the last line , I 'll do the first line . I 'm mean I think it 's doable , grad d: The poor transcribers phd g: I 'm just grad d: they 're gonna hate us . phd g: So , we we could have a round like where you do two at a time , and then the next person picks up when the first guy 's done , or something . professor f: Oh like a round , yeah , like in a a phd g: Like a , phd a: Yeah , just pairwise , professor f: yeah . phd g: I 'm actually sort of serious if it would help people do that kind o but the people who wanna work on it we should talk to them . professor f: I don't think we 're gonna collect vast amounts of data that way , phd g: So . professor f: but I think having a little bit might at least be fun for somebody like Dan to play around with , phd g: OK . grad d: I think maybe if we wanted to do that we would do it as a separate session , professor f: yeah . grad d: something like that rather than doing it during a real meeting and you know , do two people at a time then three people at a time and things like that . postdoc e: c c Can I can I have an another another question w about this ? grad d: Oh well . postdoc e: So , there are these digits , which are detached digits , but there are other words that contain the same general phon phoneme sequences . Like " wonderful " has " one " in it and and Victor Borge had a had a piece on this where he inflated the digits . Well , I wonder if there 's , an if there would be a value in having digits that are in essence embedded in real words to compare in terms of like the articulation of " one " in " wonderful " versus " one " as a digit being read . grad d: Oh ! grad c: It only sounds w good when you scream it , though . postdoc e: Well , I just wanted to offer that as a possible task professor f: Yes . postdoc e: because , you know , if we were to each read his embedded numbers words in sent in sentences cuz it 's like an entire sketch he does and I wouldn't take the inflated version . So he talks about the woman being " two - derful " , and and a But , you know , if it were to be deflated , just the normal word , it would be like a little story that we could read . postdoc e: I don't know if it would be useful for comparison , but it 's embedded numbers . grad d: I think for something like that we 'd be better off doing like  TIMIT . Well I think the question is what the research is , so  , I presume that the reason that you wanted to have these digits this way is because you wanted to actually do some research looking at the prosodic form here . professor f: So if somebody wanted to do that , if they wanted to look at the the the difference of the  phones in the digits in the context of a word versus  the digits a a non - digit word versus in digit word ,  that would be a good thing to do , but I think someone would have to express interest in that . professor f: I think , to  if you were interested in it then we could do it , for instance . grad d: We have ASR results from Liz , transcript status from Jane , and disk space and storage formats from Don . Does do we have any prefer preference on which way we wanna we wanna go ? phd g: Well I was actually gonna skip the ASR results part , in favor of getting the transcription stuff talked about grad d:   phd g: since I think that 's more important to moving forward , but  Morgan has this paper copy and if people have questions , it 's pretty preliminary in terms of ASR results because we didn't do anything fancy , but I think e just having the results there , and pointing out some main conclusions like it 's not the speaking style that differs , it 's the fact that there 's overlap that causes recognition errors . And then , the fact that it 's almost all insertion errors , which you would expect but you might also think that in the overlapped regions you would get substitutions and so forth , leads us to believe that doing a better segmentation , like your channel - based segmentation , or some kind of  , echo cancellation to get basically back down to the individual speaker utterances would be probably all that we would need to be able to do good recognition on the on the close - talking mikes . phd a: So these grad d: why don't you , if you have a hard copy , why don't you email it to the list . professor f: Yeah , so it 's the same thing ? phd g:  he he professor f: It 's the same thing I mailed to every everybody that w where it was , phd g: it it 's that paper . phd g: and it 's Let 's see , th I guess the other neat thing is it shows for sure w that the lapel , you know within speaker is bad . grad d: Horrible ? phd g: And it 's bad because it picks up the overlapping speech . phd a: So , your your ASR results were run on the channels synchronized , phd g: Yes , cuz that 's all that w had been transcribed at the time , phd a: OK . phd g: the closer t that would be very interesting for us phd b: So if phd g: because we professor f: Yeah , that 's that 's why I only used the part from use phd a: Yeah . phd b: So if there was a segment of speech this long phd g: cuz phd a: Yeah . phd b: and oh and someone said " oh , " the whole thing was passed to the recognizer ? grad d: And someone said " oh " in the front in the middle . In fact I I pulled out a couple classic examples in case you wanna u use them in your talk of phd b: That 's why there 's so many insertion errors ? grad c:   phd g: Chuck on the lapel , so Chuck wore the lapel three out of four times . phd g: yeah , and I wore the lapel once , and for me the lapel was OK . phd g: Right , but when Chuck wore the lapel and Morgan was talking there 're a couple really long utterances where Chuck is saying a few things inside , and it 's picking up all of Morgan 's words pretty well and so the rec you know , there 're error rates because of insertion Insertions aren't bounded , so with a one - word utterance and ten insertions you know you got huge error rate . So I this is sort of what we expected , but it 's nice to be able to to show it . phd g: And also I just wanted to mention briefly that ,  Andreas and I called up Dan Ellis who 's still stuck in Switzerland , and we were gonna ask him if if there 're you know , what 's out there in terms of echo cancellation and things like that . " phd g: And he We 've given him the data we have so far , so these sychronous cases where there are overlap . phd g: And he 's gonna look into trying to run some things that are out there and see how well it can do phd b: So phd g: because right now we 're not able to actually report on recognition in a real paper , like a Eurospeech paper , because it would look sort of premature . phd b: So So the idea is that you would take this big hunk where somebody 's only speaking a small amount in it , and then try to figure out where they 're speaking based on the other peopl phd g: Right . Or who 's At any point in time who 's the foreground speaker , who 's the background speaker . phd g: So there 's like grad d: But how would you do that automatically ? phd g: Well ther there 's phd a: I 've actually done some experiments with cross - correlation phd b: Right . phd a: and it seems to work pretty well to to get rid of those those overlaps , grad d:  that that 's the sort of thing that you would do . Exactly , so it 's it 's a phd b: So why do you want to do echo cancellation ? phd g: it would be techniques used from adaptive adaptive echo cancellation which I don't know enough about to talk about . phd g: But , right , and that would be similar to what you 're also trying to do , but using  , you know , more than energy phd a: Yeah . phd b: So it would be phd g: So the idea is to basically run this on the whole meeting . and get the locations , which gives you also the time boundaries of the individual speak phd b: OK . professor f: Yeah , Dave Dave  is , also gonna be doin usin playing around with echo cancellation for the nearfield farfield stuff , phd g: So . professor f: so we 'll be phd g: And I guess Espen ? This is  is he here too ? professor f: Yeah . phd g: May also be working So it would just be ver that 's really the next step because we can't do too much , you know , on term in terms of recognition results knowing that this is a big problem phd b:   phd b: I think this also ties into one of the things that Jane is gonna talk about too . grad d: I also wanted to say I have done all this chopping up of digits , postdoc e:   Definitely grad d: And and I have scripts that will extract it out from " key " files phd g: and Don should grad d: and and do all the naming automatically , phd g: OK . grad c: You 've compiled the list of , speaker names ? phd g: So that that 's it for the grad d:   grad d: and it does all sorts of matches because the way people filled out names is different on every single file so it does a very fuzzy sort of match . phd g: So at this point we can sort of finalize the naming , and so forth , grad c:   phd g: and we 're gonna basically re rewrite out these waveforms that we did because as you notice in the paper your " M O in one meeting and " M O - two " in another meeting and it 's we just need to standardize the grad c: Yeah . phd g: no it 's it 's professor f: No , I didn't notice that actually . So th I now have a script that you can just say basically look up Morgan , phd g: So professor f: Yeah . Is that something we need to talk about at the meeting , or should you just talk with Chuck at some other time ? grad c: I had some general questions just about the compression algorithms of shortening waveforms and I don't know exactly who to ask .  , yeah , which is grad d: And I assume half of it is scratch and half of it is ? grad c: I 'm not exactly sure how they partitioned it . grad c: yeah , I don't know what 's typical here , but  , it 's local though , so grad d: That doesn't matter . How do you do that ? professor f: In fact , this is an eighteen gig drive , or is it a thirty six gig drive with eighteen grad d: N grad c: Eighteen . It was a spare that Dave had around grad d: Slash N slash machine name , slash X A in all likelihood . grad d: so the the only question is how much of it The distinction between scratch and non - scratch is whether it 's backed up or not . grad d: So what you wanna do is use the scratch for stuff that you can regenerate . grad d: So , the stuff that isn't backed up is not a big deal because disks don't crash very frequently , grad c: Right .  all of this stuff can be regenerated , phd g: Yeah it 's grad c: it 's just a question grad d: Then put it all on scratch phd g: Well the grad d: because we 're ICSI is is bottlenecked by backup . grad d: So we wanna put phd g: Well I 'd leave all the All the transcript stuff shouldn't should be backed up , postdoc e:   phd g: but all the waveform Sound files should not be backed up , grad c: Yeah , I guess Right . So , I guess th the other question was then , should we shorten them , downsample them , or keep them in their original form ?  grad d: It just depends on your tools .  , because it 's not backed up and it 's just on scratch , if your sc tools can't take shortened format , I would leave them expanded , grad c: Right . grad d: so you don't have to unshorten them every single time you wanna do anything . phd g: We can downsample them , grad c: Do you think that 'd be OK ? phd g: so . phd g:  the r the front - end on the SRI recognizer just downsamples them on the fly , grad c: Yeah , I guess the only argument against downsampling is to preserve just the original files in case we want to experiment with different filtering techniques . phd g: so So that 's professor f: I I I 'm sorry phd g: Yeah , if professor f: Yeah , l  over all our data , we we want to not downsample . phd g: So we 're what we 're doing is we 're writing out  , this is just a question . We 're writing out these individual segments , that wherever there 's a time boundary from Thilo , or or Jane 's transcribers , you know , we we chop it there . phd g: And the reason is so that we can feed it to the recognizer , professor f:   grad d: Yeah , as I said , since that 's it 's regeneratable , what I would do is take downsample it , phd g: So Yeah . grad d: and compress it however you 're e the SRI recognizer wants to take it in . professor f: ye phd g: So we can't shorten them , grad c: Right . professor f: As yeah , as long as there is a a form that we can come from again , that is not downsampled , then , grad c: r Yeah . That that 's why we need more disk space professor f: uuu phd g: cuz we 're basically duplicating the originals ,  professor f: Yeah . But for for fu future research we 'll be doing it with different microphone positions and so on phd g: Oh yeah . professor f: we would like to phd b: So the SRI front - end won't take a  an an a large audio file name and then a a list of segments to chop out from that large audio file ? professor f: Yeah . phd b: They actually have to be chopped out already ? phd g: it 's better if they 're chopped out , phd b:  - huh . phd g: and and it it will be yeah , y we could probably write something to do that , but it 's actually convenient to have them chopped out cuz you can run them , you know , in different orders . grad d: And that 's the whole point about the naming conventions phd g: you can get rid of grad d: is that you could run all the English speaking , phd g: Yeah , it it 's a lot faster . grad d: all the native speakers , and all the non - native speakers , phd g: Right . You can grab everything with the word " the " in it , grad d: and all the men , and all the women . phd g: and it 's That 's a lot quicker than actually trying to access the wavefile each time , find the time boundaries and So in principle , yeah , you could do that , phd b: I don't I don't think that 's really right . phd g: but it 's but it 's  grad d: " That 's just not right , man . " The the point phd g: These are long These are long grad d: So so s For example , what if you wanted to run run all the native speakers . grad d: Right , so if if you did it that way you would have to generate a program that looks in the database somewhere , extracts out the language , finds the time - marks for that particular one , do it that way . The way they 're doing it , you have that already extracted and it 's embedded in the file name . And so , you know , you just say phd g: We - yeah that 's so that 's part of it grad d: y so you just say you know " asterisk E asterisk dot wave " , and you get what you want . And the other part is just that once they 're written out it it is a lot faster to to process them . Otherwise , you 're just accessing grad d: This is all just temporary access , so I don't I think it 's all just It 's fine . Two gig ? phd g: So we 're also looking at these in Waves like for the alignments and so forth . phd g: You need to s have these small files , and in fact , even for the Transcriber program  grad d: Yes you can . phd g: Yeah , if you try to load s really long waveform into X Waves , you 'll be waiting there for phd b: No , I I 'm not suggesting you load a long wave file , phd g: Oh phd b: I 'm just saying you give it a start and an end time . grad d: I th w The transcribers didn't have any problem with that did they Jane ? postdoc e: What 's th u w in what respect ? phd g: Loading the long phd a: No , with the Transcriber tool , it 's no problem . phd g: It takes a very long ti phd a: Yeah just to load a transcription postdoc e: In the in   grad d: Are you talking about Transcriber or X Waves ? phd g: Huh . phd g: Actually , you 're talking about Transcriber , right ? phd a: Yeah . grad d: And they were loading the full mixed files then , postdoc e: Yeah . Well we we have a problem with that , you know , time - wise on a It - it 's a lot slower to load in a long file , grad d:  . phd g: and also to check the file , so if you have a transcript , grad d: Well regardless , it 's professor f: Yeah . phd g:  it 's I I think overall you could get everything to work by accessing the same waveform and trying to find two you know , the begin and end times .  , but I think it 's more efficient , if we have the storage space , to have the small ones . grad d: and , it 's no problem , right ? phd g: Yeah , it 's grad d: Because it 's not backed up . grad d: So we just phd g: It 's it 's just grad d: If we don't have a spare disk sitting around we go out and we buy ourselves an eighty gigabyte drive and make it all scratch space . phd g: Yeah , so these wouldn't be backed up , the postdoc e: Yeah . grad d: So remind me afterward phd g: And grad d: and I 'll and we 'll look at your disk and see where to put stuff .  , I could just u do a DU on it right ? And just see which how much is on each So . Alright so , first of all , there was a an interest in the transcribe transcription , checking procedures and and I can tell you first , to go through the steps although you 've probably seen them .  , as you might imagine , when you 're dealing with , r really c a fair number of words , and  , @ @ natural speech which means s self - repairs and all these other factors , that there 're lots of things to be , s standardized and streamlined and checked on . And , so , I did a bunch of checks , and the first thing I did was obviously a spell - check . And at that point I discovered certain things like , " accommodate " with one " M " , that kind of thing . And then , in addition to that , I did an exhaustive listing of the forms in the data file , which included n detecting things like f faulty punctuation and things phd b: I 'm I 'm sorry to interrupt postdoc e: Yeah ? phd b: you could could I just back up a little bit postdoc e: Sure , please , phd b: and postdoc e: yeah , please , please . phd b: So you 're doing these So the whole process is that the transcribers get the conversation postdoc e: Yeah , yeah , yeah . phd b: And then when they 're finished with it , it comes to you , postdoc e: That 's right . And so , I do a an exhaustive listing of the forms Actually , I will go through this in in order , so if if we could maybe wait and stick keep that for a second cuz we 're not ready for that . grad d: So on the fifth page , seven down postdoc e: Yeah , yeah , yeah , yeah . Exactly ! Exactly ! Alright so , a spelling check first then an exhaustive listing of the ,  all the forms in the data with the punctuation attached and at that point I pick up things like , oh , you know , word followed by two commas . But there 's w And that that 's done with the assumption that pronunciation variants can be handled . So for things like " and " , the fact that someone doesn't say the " D " ,  that 's not important enough to capture in the transcription because a a good pronunciation , you know , model would be able to handle that . However , things like " cuz " where you 're lacking an entire very prominent first syllable , and furthermore , it 's a form that 's specific to spoken language , those are r reasons f for those reasons I I kept that separate , and used the convention of using " CUZ " for that form , however , glossing it so that it 's possible with the script to plug in the full orthographic form for that one , and a couple of others , not many . So " wanna " is another one , " going "  , " gonna " is another one , with just the assumption , again , that this th these are things which it 's not really fair to a c consider expect that a pronunciation model , to handle . And Chuck , you in you indicated that " cuz " is is one of those that 's handled in a different way also , didn't you ? Did I phd b: I don't remember . postdoc e: but someone told me that in fact " cuz " is treated differently in , i u in this context because of that r reason that , it 's a little bit farther than a pronunciation variant . OK , so after that , let 's see , phd b: So that was part of the spell - check , or was that that was after the spell - check ? postdoc e:  . Well so when I get the exhau So the spell - check picks up those words because they 're not in the dictionary . postdoc e: So it gets " cuz " and " wanna " and that grad d: And then you gloss them ? postdoc e: Yeah ,   Run it through I have a sed You know , so I do sed script saying whenever you see " gonna " you know , " convert it to gonna " , you know , " gloss equals quote going - to quote " , you know . OK , I also wrote a script which will , retrieve anything in curly brackets , or anything which I 've classified as an acronym , and a pronounced acronym . So if it 's " ACL " then it 's " A " underscore " C " underscore " L " . grad d: And so so your list here , are these ones that actually occurred in the meetings ? postdoc e: And the th Yes . phd g: can I ask a question about the glossing ,  before we go on ? postdoc e: Yeah . phd g: So , for a word like " because " is it that it 's always predictably " because " ?  , is " CUZ " always meaning " because " ? postdoc e: Yes , but not the reverse . So sometimes people will say " because " in the meeting , and if if they actually said " because " , then it 's written as " because " with no w " cuz " doesn't even figure into the equation . professor f: But but in our meetings people don't say " hey cuz how you doing ? " phd g: Beca - because Right . phd g: so , I guess So , from the point of view of postdoc e: That 's a good point . phd g: The the only problem is that with for the recognition we we map it to " because " , grad d: Well , phd g: and so if we know that " CUZ " postdoc e: That 's fine . phd g: but , we don't grad d: You have the gloss form so you always replace it . postdoc e: and he 's bee he has a glo he has a script that grad c: I replace the " cuz " with " because " if it 's glossed . grad c: And phd g: But then there are other glosses that we don't replace , right ? Because postdoc e: Yes . postdoc e: on the different on the different types of comments , which we 'll which we 'll see in just a second . postdoc e: So the pronounceable acronyms get underscores , the things in curly brackets are viewed as comments . w And maybe we 'll expand that grad d:  postdoc e: but the but the comments are , of four types mainly right now . grad d: Can ca postdoc e: Another type is ,  grad d: So a are we done with acronyms ? Cuz I had a question on what what this meant . postdoc e: OK so , gloss is things like replacing the full form u with the , more abbreviated one to the left .  , then you have if it 's  , there 're a couple different types of elements that can happen that aren't really properly words , and wo some of them are laughs and breathes , so we have  that 's prepended with a v a tag of " VOC " . phd a: Whew !  postdoc e: And the non - vocal ones are like door - slams and tappings , and that 's prepended with a no non - vocalization . phd b: So then it just an ending curly brace there , or is there something else in there . postdoc e: Oh yeah , so i e this would grad d: A comment , basically . postdoc e: And then the no non - vocalization would be something like a door - slam . And then the third type right now , is m things that fall in the category of comments about what 's happening . So it could be something like , you know , " referring to so - and - so " , " talking about such - and - such " , you know , " looking at so - and - so " . phd b: on the middle t So , in the first case that gloss applies to the word to the left . But in the middle two Th - it 's not applying to anything , right ? postdoc e: Yeah , and this gets substituted here . grad d: Well the " QUAL " can be The " QUAL " is applying to the left . postdoc e: Well , and actually , it is true that , with respect to " laugh " , there 's another one which is " while laughing " , grad d: " While laughing " . postdoc e: and that is , i i An argument could be made for this tur turning that into a qualitative statement because it 's talking about the thing that preceded it , but at present we haven't been , coding the exact scope of laughing , you know , and so to have " while laughing " , you know that it happened somewhere in there which could well mean that it occurred separately and following , or , you know , including some of the utterances to the left . Haven't been awfully precise about that , but I have here , now we 're about to get to the to this now , I have frequencies . But , the very front page deals with this , final c pa  , aspect of the standardization which has to do with the spoken forms like "  -  " and "  -  " and " ha " and "  -  " and all these different types . And , someone pointed out to me , this might have been Chuck , about ,  about how a recognizer , if it 's looking for "  - hmmm " with three M 's , and it 's transcribed with two M 's , that it might  , that it might increase the error rate which is which would really be a shame because  , I p I personally w would not be able to make a claim that those are dr dramatically different items . postdoc e: I I should say grad d: So it 's a small list . So , I 'm gonna I 'm gonna I 'm gonna check grad d: That that 's known as " found data " . I got It was stored in a place I didn't expect , grad c: It 's like the z Zapruder Film . So I 'll I 'll be able to get through that tonight , and then everyth i well , actually later today probably . postdoc e: And I made it so that these are , with a couple exceptions but , things that you wouldn't find in the spell - checker so that they 'll show up really easily . And ,  grad c: Jane , can I ask you a question ? What 's that very last one correspond to ? postdoc e: Sure . grad c: is that like someone 's like burning or some such thing ? postdoc e: So - c I haven't listened to it so I don't know . grad c: Like their hair 's on fire ? postdoc e: I haven't heard it actually . grad d: Ah ! phd a: It 's the Castle of Ah ! phd g: Actually we we gave this to our pronunciation person , grad c: it looks like that . postdoc e: Did she hear the th did she actually hear it ? Cuz I haven't heard it . phd g: No , we just gave her a list of words that , you know , weren't in our dictionary and so of course it picked up stuff like this , and she just didn't listen so she didn't know . Yeah I 'm curious to se hear what it is , but I didn't know wanna change it to something else until I knew . phd g: Maybe it 's " argh " ? postdoc e: Well , sss , you know phd g:  grad c: But that 's not really like postdoc e: Hhh . grad c: No one really says " argh , " you know , postdoc e:  phd g: Yeah . Right , no one say grad c: it 's not professor f: Well , you just did . phd b: Except for now ! grad c: Well , there 's another there 's another word error . grad d: Ah ! postdoc e: phd g: So , Jane , what 's the d grad d: Maybe he died while dictating . phd g: I have one question about the the " EH " versus like the " AH " and the "  " . postdoc e: That 's partly a nonnative - native thing , phd g: OK . phd g:  postdoc e: But it 's mostly non - native phd a: H phd b: That 's " eh " versus " ah " ? phd g: S OK . grad d: Eh ? phd g: " Eh , " yeah right , cuz there were were some speakers that did definite " eh 's " postdoc e:   phd g: but right now we phd b: They were the Canadians , right ? professor f: Canadians , yeah , yeah , yeah . phd g: So , it it 's actually probably good for us to know the difference between the real " eh " and the one that 's just like "  " or transcribed " aaa " postdoc e: Exactly . phd g: cuz in like in Switchboard , you would see e all of these forms , but they all were like "  " . grad d: You mean just the single letter " a " as in the particle ? phd a: The transcription or grad d: Article . phd g: No , no ,  like the the "  " , postdoc e: "  " . grad d: I 'm just these poor transcribers , they 're gonna hate this meeting . phd g: But you 're a native German speaker so it 's not a not a issue for phd a: Yeah . phd g: So it 's like Japanese and Spanish postdoc e: Yeah I I think you 've  - huh , yeah . phd g: and grad d: I didn't get that , postdoc e: That makes sense . postdoc e: Yeah , and so , you know , th th I have there are some , Americans who who are using this " eh " too , and I haven't listened to it systematically , maybe with some of them , they 'd end up being "  's " but , I my spot - checking has made me think that we do have " eh " in also , American e e data represented here . But any case , that 's the this is reduced down from really quite a long a much longer list , phd g: Yeah this is great . grad d: Yeah , it 's good , postdoc e: and this is grad d: yeah . postdoc e: functionally pretty , you know , also It was fascinating , I was listening to some of these , I guess two nights ago , and it 's just hilarious to liste to to do a search for the "  -  's " . postdoc e: Just I wanted to say I w think it would be fun to make a montage of it because there 's a "   postdoc e: All these different vocal tracts , you know , but it 's it 's the same item .  , then the acronyms y and the ones in parentheses are ones which the transcriber wasn't sure of , grad d: Oh I see . postdoc e: and I haven't been able to listen to to to clarify , but you can see that the parenthesis convention makes it very easy to find them grad d: o How about question mark ? postdoc e: cuz it 's the only place where where they 're used . grad d: So they so it 's " PLP ? " postdoc e: Exactly . Sometimes the contrastive stress is showing up , and ,  professor f: I 'm sorry , I I got lost here . What - w what 's the difference between the parenthesized acronym and the non - parenthesized ? postdoc e: The parenthesized is something that the transcriber thought was ANN , but wasn't entirely sure . So I 'd need to go back or someone needs to go back , and say , you know , yes or no , professor f: Ah . postdoc e: But the parentheses are used only in that context in the transcripts , of of noti noticing that there 's something uncertain . grad d: Yeah , P - make is phd g: Yeah  cuz they they have no idea , grad d: That 's a good one . phd g: but it 's professor f: I I don't recognize a lot of these . grad d: I know ! I I was saying that I think a lot of them are the Networks meeting . phd g: and the PTA was in these , topics about children , postdoc e: Yeah . phd g: Is the P - PTA working ? postdoc e: Right and sometimes , you see a couple of these that are actually " OK 's " so it 's it 's may be that they got to the point where  it was low enough understandable understandability that they weren't entirely sure the person said " OK . " You know , so it isn't really necessarily a an undecipherable acronym , grad c: There 's a lot of " OK 's " . This professor f: The number to the left is the number of incidences ? grad d: Count . professor f: So CTS is really big here , grad d: Yeah , I wonder what it is . phd a: So what is the difference between " papers rustling " and " rustling papers " ? professor f: IP , I know what IP is . postdoc e: But , I I 'm a little hesitant to to collapse across categories unless I actually listen to them . OK well professor f: Wh - the self - referential aspect of these these p phd g: I 'm wai grad c: Yeah . phd g: Well this is exactly how people will prove that these meetings do differ because we 're recording , right ? grad d: Yes . phd g: Y no normally you don't go around saying , " Now you 've said it six times . phd g: Now you 've said " postdoc e: But did you notice that there were seven hundred and eighty five instances of " OK " ? phd a: Seven hundred eighty - five instances . grad d: And that 's an underestimate postdoc e: Extra forty one if it 's questioned . grad c: Is this after like did you do some  replacements for all the different form of " OK " to this ? professor f: Yeah . phd b: Wait a minute , w s professor f: So now we 're up to seven hundred and eighty eight . postdoc e: Yeah that 's grad c: Although , what 's there 's one with a slash after it . phd b: Was that somewhere where they were gonna say " new speaker " or something ? postdoc e: No , I looked for that , but that doesn't actually exist . postdoc e: I i it 's the only grad c: There 's postdoc e: it 's the only pattern that has a slash after it , and I think it 's it 's an epiphenomenon . grad d: So I 'll just I was just looking at the bottom of page three there , is that " to be " or " not to be " . phd b: There 's no tilde in front of it , postdoc e: Oh that 's cute . " postdoc e: There is th one Y well , no , that 's r that 's legitimate . So now , comments , you can see they 're listed again , same deal , with exhaustive listing of everything found in everything except for these final th thirty minutes . grad d: OK so , on some of these QUALs , postdoc e: Yeah . grad d: are they really QUALs , or are they glosses ? So like there 's a " QUAL TCL " . professor f: What 's a QUAL ? grad d: Oh I see , I see . grad c: Sh - shouldn't it be " QUAL TICKLE " or something ? grad d: It wasn't said " TCL " . grad c: Like it 's not postdoc e: On the in the actual script in the actual transcript , I s I So this this happens in the very first one . postdoc e: Because we they didn't say " TCL " , they said " tickle " . professor f: I f I forget , what 's QUAL ? postdoc e: Qual - qualifier . grad c: It 's not something you wanna replace with postdoc e: Comment or contextual comment . phd b: So they didn't mean " tickle " as in Elmo , grad c: but phd a: Tickle ? professor f: Yeah . phd g: But at some point  , we probably shoul grad d: We 'll probably add it to the language model . phd b: Add what , Liz ? grad d: We can go on lan lan add it to both dictionary and language model . phd g: it 's in the language model , w yeah , but it so it 's the pronunciation model that has to have a pronunciation of " tickle " . Right ? phd a: " tickle " is pronounced " tickle " ? phd b: What are you saying ? grad d: It 's pronounced the same it 's pronounced the same as the verb . phd g: I 'm sorry ! grad d: So I think it 's the language model that makes it different . What I meant is that there should be a pronunciation " tickle " for TCL as a word . phd g: And that word in the in , you know , it stays in the language model wherever it was . phd g: Yeah you never would put " tickle " in the language model in that form , postdoc e:  grad d: Right . There 's actually a bunch of cases like this with people 's names and phd b: So how w there 'd be a problem for doing the language modeling then with our transcripts the way they are . Yeah so th th there there 's a few cases like that where the  , the word needs to be spelled out in in a consistent way as it would appear in the language , but there 's not very many of these . grad d: And and you 'll ha you 'll have to do it sychronously . grad d: Right , so y so , whoever 's creating the new models , will have to also go through the transcripts and change them synchronously . We have this there is this thing I was gonna talk to you about at some point about , you know , what do we do with the dictionary as we 're up updating the dictionary , these changes have to be consistent with what 's in the Like spelling people 's names and so forth . If we make a spelling correction to their name , like someone had Deborah Tannen 's name mispelled , and since we know who that is , you know , we could correct it , grad d: You can correct it . phd g: but but we need to make sure we have the mispel If it doesn't get corrected we have to have a pronunciation as a mispelled word in the dictionary . postdoc e: Well , of course now the the Tannen corre the spelling c change . So if there 's things that get corrected before we get them , it 's it 's not an issue , postdoc e:   phd g: but if there 's things that  , we change later , then we always have to keep our the dictionary up to date . And then , yeah , in the case of " tickle " I guess we would just have a , you know , word " TCL " which phd b:   phd g: which normally would be an acronym , you know , " TCL " grad d: Right . postdoc e: " ICSI " is is one of those that sometimes people pronounce and sometimes they say " ICSI . postdoc e: So , those that are l are listed in the acronyms , I actually know phd g: Oh yeah . The others , e those really do need to be listened to cuz I haven't been able to go to all the IC ICSI things , phd g: Right , exactly . postdoc e: and and until they 've been listened to they stay as " ICSI " . professor f: Don and I were just noticing , love this one over on page three , " vocal vocal gesture mimicking sound of screwing something into head to hold mike in place . postdoc e: It was ! In fact , it was ! Yeah ! grad d: A lot of these are me the the " beep is said with a high pit high pitch and lengthening . grad d: That was the I was imitating  , beeping out postdoc e: Yeah , that 's it . phd g: Oh there is something spelled out " BEEEEEEP " grad c:  postdoc e: That 's it . Because he was saying , " How many E 's do I have to allow for ? " grad c: You need a lot of grad d: What I meant was " beep " . postdoc e: And those of course get get picked up in the frequency check grad d: glosses . postdoc e: and you know  it gets kicked out in the spelling , and it also gets kicked out in the , freq frequency listing . postdoc e: I have the there 're various things like " breathe " versus " breath " versus " inhale " and , hhh , you know , I don't know . I I think they don't have any implications for anything else so it 's like I 'm tempted to leave them for now an and It 's easy enough to find them when they 're in curly brackets . professor f: " Sings finale - type song " grad c: Yeah , that was in the first meeting . grad d: postdoc e: Yeah , but I don't actually remember what it was . " postdoc e:  Chuck Chuck led to a refinement here which is to add " NUMS " if these are parts of the read numbers . Now you already know i that I had , in places where they hadn't transcribed numbers , I put " numbers " in place of any kind of numbers , but there are places where they , it th this convention came later an and at the very first digits task in some transcripts they actually transcribed numbers . And , d Chuck pointed out that this is read speech , and it 's nice to have the option of ignoring it for certain other prob  p  , things . And that 's why there 's this other tag here which occurs a hundred and five or three hundred and five times right now which is just well n n " NUMS " by itself grad d: " NUMS " , yeah .  , i with the sed command you can really just change it however you want because it 's systematically encoded , you know ? grad d: Yep . postdoc e: Have to think about what 's the best for for the overall purposes , but in any case , " numbers " and " NUMS " are a part of this digits task thing . And actually , th  , the reason I b did it this way was because I initially started out with the other version , you have the numbers and you have the full form and the parentheses , however sometimes people stumble over these numbers they 're saying . And there 's no way of capturing that if you 're putting the numbers off to the side . You can't have the seven and grad d: So what 's to the left of these ? postdoc e: The left is i so example the very first one , grad d:   postdoc e: And then , in here , " NUMS " , so it 's not going to be mistaken as a gloss . grad d: OK now , the other example is , in the glosses right there , postdoc e: Thank you . grad d: What what 's to the left of that ? postdoc e: Well now In that case it 's people saying things like " one one one dash so - and - so " or they 're saying  " two  zero " whatever . postdoc e: And in that case , it 's part of the numbers task , and it 's not gonna be included in the read digits anyway , phd b: So there will be a " NUMS " tag on those lines ? postdoc e: so I m in the  There is . postdoc e: So , so gloss in the same line that would have " gloss quote one one one dash one thirty " , you 'd have a gloss at the end of the line saying , " curly bracket NUMS curly bracket " . postdoc e: So if you if you did a , a " grep minus V nums " phd g: Oh , so you could do " grep minus V nums " . phd g: So there wouldn't be something like i if somebody said something like , " Boy , I 'm really tired , OK . Cuz I was doing the " grep minus V " quick and dirty and looked like that was working OK , postdoc e:   Now why do we what 's the reason for having like the point five have the " NUMS " on it ? Is that just like when they 're talking about their data or something ? postdoc e: This is more because phd g: Or postdoc e: Yeah . Oh these are all these , the " NUMS point " , this all where they 're saying " point " something or other . phd g: These are all like inside the spontaneous postdoc e: And the other thing too is for readability of the transcript .  if you 're trying to follow this while you 're reading it it 's really hard to read , you know eh , " so in the data column five has " , you know , " one point five compared to seventy nine point six " , it 's like when you see the words it 's really hard to follow the argument . And this is just really a a way of someone who would handle th the data in a more discourse - y way to be able to follow what 's being said . postdoc e: So this is where Chuck 's , overall h architecture comes in , phd g: I see .  , there will be scripts that are written to convert it into these t these main two uses and th some scripts will take it down th e into a f a for ta take it to a format that 's usable for the recognizer an  , other scripts will take it to a form that 's usable for the for linguistics an and discourse analysis . These will just be things that are generated , grad d: Right postdoc e: and e by using scripts . postdoc e: When things change then the the script will cham change but the but there won't be stored copies of in different versions of things . phd g: So , I guess I 'd have one request here which is just , maybe to make it more robust , th that the tag , whatever you would choose for this type of " NUMS " where it 's inside the spontaneous speech , is different than the tag that you use for the read speech . phd g: that way w if we make a mistake parsing , or something , we don't see the " point five " , or or it 's not there , then we phd b:   phd g: a Just an And actually for things like " seven eighths " , or people do fractions too I guess , you maybe you want one overall tag for sort of that would be similar to that , postdoc e: Except phd g: or As long as they 're sep as they 're different strings that we that 'll make our p sort of processing more robust . postdoc e: Well phd g: Cuz we really will get rid of everything that has the " NUMS " string in it . phd b: I suppose what you could do is just make sure that you get rid of everything that has " curly brace NUMS curly brace " . postdoc e: You know , as I said I was considering changing it to " digits " . And , it just i you know , it 's just a matter of deciding on whatever it is , and being sure the scripts know . phd g: It would probably be safer , if you 're willing , to have a separate tag just because  , then we know for sure .  , phd b: Yeah , and it makes it I guess the thing about phd g: but it it 's probably not hard for a person to tell the difference phd b: Yeah . phd g: because one 's in the context of a you know , a transcribed word string , phd b: Right . postdoc e: The other thing is you can get really so minute with these things phd g: and So postdoc e: and increase the size of the files and the re and decrease the readability to such an extent by simply something like " percent " . Now I I could have adopted a similar convention for " percent " , but somehow percent is not so hard , you know ? grad d:  . postdoc e: i It 's just when you have these points and you 're trying to figure out where the decimal places are And we could always add it later . And you 'll find both of those in one of these meetings , where he 's saying " well the first point I wanna make is so - and - so " and he goes through four points , and also has all these decimals . phd b: what does the SRI recognizer output for things like that ? " seven point five " . phd b: Right , the word " seven " ? grad d: Well , the numbers ? phd b: The number " seven " ? phd g: The word . professor f: So I 'd so " I 'd like I 'd like to talk about point five " . phd g: it 's the same point , actually , the the p you know , the word " to " and the word y th " going to " and " to go to " those are two different " to 's " and so there 's no distinction there . phd g: It 's just just the word " point " has Yeah , every word has only one , yeah e one version even if even if it 's A actually even like the word " read " and " read " Those are two different words . phd g: So , yeah , I I like the idea of having this in there , I just I was a little bit worried that , the tag for removing the read speech because i What if we have like " read letters " or , I don't know , grad d: We might wanna just a separate tag that says it 's read . OK ? Are we done ? postdoc e: Well I wanted to say also regarding the channelized data , grad d: Oh , I guess we 're not done . postdoc e: that , Thilo requested , that we ge get some segments done by hand to e e s reduce the size of the time bins wh like was Chuc - Chuck was mentioning earlier that , that , if you if you said , " Oh " and it was in part of a really long , s complex , overlapping segment , that the same start and end times would be held for that one grad d: Well postdoc e: as for the longer utterances , grad d: We did that for one meeting , right , postdoc e: and grad d: so you have that data don't you ? phd a: Yeah , that 's the training data . postdoc e: And he requested that there be , similar , samples done for five minute stretches c involving a variety of speakers and overlapping secti sections . postdoc e: He gave me he did the very nice , he he did some shopping through the data and found segments that would be useful . In addition the I 've I have the transcribers expanding the amount that they 're doing actually . postdoc e: So right now , I know that as of today we got an extra fifteen minutes of that type , and I 'm having them expand the realm on either side of these places where they 've already started . postdoc e: But if if you know , and I and he 's gonna give me some more sections that that he thinks would be useful for this purpose . postdoc e: Because it 's true , if we could do the the more fine grained tuning of this , using an algorithm , that would be so much more efficient . phd a: So I I thought we we sh we sh perhaps we should try to to start with those channelized versions just to just to try it . Give it Give one tr transcriber the the channelized version of of my speech - nonspeech detection and look if if that 's helpful for them , or just let them try if if that 's better or If they if they can postdoc e: You mean to start from scratch f in a brand new transcript ? phd a: Yeah . As it stands we 're still in the phase of sort of , cleaning up the existing data getting things , in i m more tight tightly time  , aligned . I also wanna tell  , I also wanted to r raise the issue that OK so , there 's this idea we 're gonna have this master copy of the transcript , it 's gonna be modified by scripts t into these two different functions . postdoc e: So right now we 've taken this i initial one , it was a single channel basically the way it was input . And now , thanks to the advances made in the interface , we can from now on use the channelized part , and , any changes that are made get made in the channelized version kind of thing . But I wanted to get all the finished all the checks phd b: Yeah , so that has implications for your script . So , have those e e the vis the ten hours that have been transcribed already , have those been channelized ? And I know I 've seen @ @ I 've seen they 've been channelized , postdoc e: Yes , they have . grad d: All ten hours ? grad c: but postdoc e: Except for the missing thirty minutes . grad c: have they  have they been has the time have the time markings been adjusted , p on a per channel grad d: Great . postdoc e: for for a total of like twenty m f for a total of Let 's see , four times total of about an thirty minutes . grad c: I guess , I don't know if we should talk about this now , or not , but I grad d: Well it 's just we 're missing tea . grad c: No , but  my question is like should I wait until all of those are processed , and channelized , like the time markings are adjusted before I do all the processing , and we start like branching off into the into the our layer of  transcripts . postdoc e: Well , you know the problem the problem is that some some of the adjustments that they 're making are to bring are to combine bins that were time bins which were previously separate . postdoc e: And so , i i i it 's true that it 's likely to be adjusted in the way that the words are more complete . postdoc e: so I it 's gonna be a more reliable thing and I 'm not sure grad c:  I 'm sure about that , postdoc e: Yeah . grad c: but do you have like a time frame when you can expect like all of it to be done , or when you expect them to finish it , or postdoc e: Well partly it depends on how  , how e effective it will be to apply an algorithm because i this takes time , grad c: Yeah . phd b: So right now the what you 're doing is you 're taking the  , the o original version and you 're sort of channelizing yourself , right ? grad c: Yeah .  i if the time markings aren't different across channels , like the channelized version really doesn't have any more information . grad c: So , I was just  , originally I had done before like the channelized versions were coming out . grad c: phd b: So I I th I think probably the way it 'll go is that , you know , when we make this first general version and then start working on the script , that script @ @ that will be ma you know primarily come from what you 've done , we 'll need to work on a channelized version of those originals . phd b: And so it should be pretty much identical to what you have t except for the one that they 've already tightened the boundaries on . phd b: So postdoc e: Yeah ,  phd b: and then probably what will happen is as the transcribers finish tightening more and more , you know , that original version will get updated postdoc e: yeah . phd b: But the I guess the ef the effect for you guys , because you 're pulling out the little wave forms into separate ones , that would mean these boundaries are constantly changing you 'd have to constantly re rerun that , grad c: I know . phd g: I I think the harder part is making sure that the transc the transcription phd b: OK . phd g: So if you b merge two things , then you know that it 's the sum of the transcripts , but if you split inside something , you don't where the word which words moved . phd g: And that 's wh that 's where it becomes a little bit  , having to rerun the processing . grad c: You know , if I just have to run three scripts to extract it all and let it run on my computer for an hour and a half , or however long it takes to parse and create all the reference file , that 's not a problem . And I know exactly like what the steps will work what 's going on , in the editing process , phd b: Yeah . postdoc e: So that 's I  I could there were other checks that I did , but it 's I think that we 've unless you think there 's anything else , I think that I 've covered it 