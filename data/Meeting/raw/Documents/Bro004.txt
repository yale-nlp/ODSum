phd e: Ah grad f: Wh - what causes the crash ? phd a: Did you fix something ? phd c: Hello . grad f: Oh , maybe it 's the turning turning off and turning on of the mike , right ? professor b: you think that 's you ? Oh . phd e: Mmm , channel five ? Doesn't work ? professor b: Yeah , that 's the mike number there , mike number five , and channel channel four . So  I also copied  the results that we all got in the mail I think from  from OGI and we 'll go go through them also . phd d: The PLP , the PLP with JRASTA , the MSG , and the MFCC from the baseline Aurora . We 've trained  several neural networks on so on the TI - digits English and on the Italian data and also on the broad  English  French and  Spanish databases . Mmm , so there 's our result tables here , for the tandem approach , and  , actually what we we @ @ observed is that if the network is trained on the task data it works pretty well . Our our  There 's a We 're pausing for a photo phd c: Chicken on the grill . phd a: How about over th from the front of the room ? phd c: Yeah , it 's longer . And  actually we have  , results are similar Only on , phd a: Do you mean if it 's trained only on On data from just that task , phd d: yeah . But actually we didn't train network on  both types of data   phonetically ba phonetically balanced  data and task data . So , professor b: So how  clearly it 's gonna be good then phd a: So what 's th professor b: but the question is how much worse is it if you have broad data ?  , my assump From what I saw from the earlier results ,  I guess last week , was that  , if you trained on one language and tested on another , say , that the results were were relatively poor . professor b: But but the question is if you train on one language but you have a broad coverage and then test in another , does that is that improve things i c in comparison ? phd d: If we use the same language ? professor b: No , no , no . Different lang So  If you train on TI - digits and test on Italian digits , you do poorly , let 's say . professor b: I don't have the numbers in front of me , phd d: But Yeah but I did not  do that . E So , you didn't train on TIMIT and test on on Italian digits , say ? phd d: We No , we did four four kind of of testing , actually . The second test is trained on a single language  with broad database , but the same language as the t task data . The third test is by using ,  the three language database professor b: W which in phd d: and the fourth is professor b: It has three languages . That 's including the w the the phd d: This includes professor b: the one that it 's phd d: Yeah . phd d: Yeah And the fourth test is  excluding from these three languages the language that is the task language . So  for  TI - digits for ins example  when we go from TI - digits training to TIMIT training  we lose  around ten percent ,  . And then when we jump to the multilingual data it 's  it become worse and , well Around  , let 's say , twenty perc twenty percent further . phd d: But the first step is al already removing the task s specific from from phd a: Already , right right right . phd a: So they were sort of building here ? phd d: And we lose phd a: OK ? phd d: Yeah .  So , basically when it 's trained on the the multilingual broad data  or number so , the the ratio of our error rates  with the baseline error rate is around  one point one . professor b: I i if you compare everything to the first case at the baseline , you get something like one point one for the for the using the same language but a different task , and something like one point three for three three languages broad stuff . phd d: Tas - task data professor b: I I I meant something different by baseline phd d: we are u Yeah . professor b: So if we call a factor of w just one , just normalized to one , the word error rate that you have for using TI - digits as as training and TI - digits as test , phd d: Mmm . professor b: If we call that " one " , then what you 're saying is that the word error rate for the same language but using  different training data than you 're testing on , say TIMIT and so forth , it 's one point one . professor b: you do go to three languages including the English , it 's something like one point three . professor b: And if you exclude English , from this combination , what 's that ? phd d: If we exclude English ,  there is not much difference with the data with English . So what what it 's saying here is just that " yes , there is a reduction in performance , when you don't  have the s when you don't have  phd a: Task data . So it 's So when you go to a different task , there 's actually not so different . It 's when you went to these So what 's the difference between two and three ? Between the one point one case and the one point four case ? I 'm confused . The only difference it 's is that it 's multilingual  professor b: Cuz in both in both both of those cases , you don't have the same task . professor b: So is is the training data for the for this one point four case does it include the training data for the one point one case ? phd d:  yeah . professor b: How m how much bigger is it ? phd d:  It 's two times , grad f: Yeah ,  . professor b: So it 's two times , but it includes the but it includes the broad English data . professor b: So you have band - limited TIMIT , gave you  almost as good as a result as using TI - digits on a TI - digits test . OK ? phd d:  ? professor b:  and  But , when you add in more training data but keep the neural net the same size , it  performs worse on the TI - digits . OK , now all of this is This is noisy TI - digits , I assume ? Both training and test ? phd d:  professor b: Yeah . We we we may just need to  So  it 's interesting that h going to a different different task didn't seem to hurt us that much , and going to a different language  It doesn't seem to matter The difference between three and four is not particularly great , so that means that whether you have the language in or not is not such a big deal . professor b: It sounds like   we may need to have more of  things that are similar to a target language or  . You have the same number of parameters in the neural net , you haven't increased the size of the neural net , and maybe there 's just just not enough complexity to it to represent the variab increased variability in the in the training set .  So , what about So these are results with  th that you 're describing now , that they are pretty similar for the different features or or  phd d: let me check . For the PLP with JRASTA the the we This is quite the same tendency , with a slight increase of the error rate ,  if we go to to TIMIT . There there is a difference actually with b between PLP and JRASTA is that JRASTA seems to perform better with the highly mismatched condition but slightly slightly worse for the well matched condition . professor b: I have a suggestion , actually , even though it 'll delay us slightly , would would you mind running into the other room and making copies of this ? Cuz we 're all sort of If we c if we could look at it , while we 're talking , I think it 'd be phd d: Yeah , yeah . professor b: I 'll I 'll sing a song or dance or something while you do it , too . phd a: The  What was Was this number forty or It was roughly the same as this one , he said ? When you had the two language versus the three language ? professor b:  . That 's interesting because it it seems like what it 's saying is not so much that you got hurt  because you  didn't have so much representation of English , because in the other case you don't get hurt any more , at least when it seemed like  it it might simply be a case that you have something that is just much more diverse , phd a:   I wonder were  all three of these nets using the same output ? This multi - language  labelling ? grad f: He was using  sixty - four phonemes from SAMPA . phd a: So this would From this you would say , " well , it doesn't really matter if we put Finnish into the training of the neural net , if there 's gonna be , you know , Finnish in the test data . " Right ? professor b: Well , it 's it sounds  , we have to be careful , cuz we haven't gotten a good result yet . professor b: But I I I I think it does suggest that it 's not so much   cross language as cross type of speech . professor b: It 's it 's  But we did Oh yeah , the other thing I was asking him , though , is that I think that in the case Yeah , you you do have to be careful because of com compounded results . I think we got some earlier results in which you trained on one language and tested on another and you didn't have three , but you just had one language . Didn - Wasn't there something of that ? Where you , say , trained on Spanish and tested on on TI - digits , or the other way around ? Something like that ? phd e: No . professor b: This may have been what I was asking before , Stephane , but but , wasn't there something that you did , where you trained on one language and tested on another ?  no no mixture but just grad f: I 'll get it for you . professor b: We 've never just trained on one lang phd d: Training on a single language , you mean , and testing on the other one ? professor b: Yeah . phd d: So the only task that 's similar to this is the training on two languages , and that professor b: But we 've done a bunch of things where we just trained on one language . Either thi this is test with  the same language but from the broad data , or it 's test with  different languages also from the broad data , excluding the So , it 's it 's three or three and four . phd e: The early experiment that phd a: Did you do different languages from digits ? phd d:  . You mean training digits on one language and using the net to recognize on the other ? phd a: Digits on another language ? phd d: No . professor b:  What phd c: These numbers are  ratio to baseline ? professor b: So ,  wha what 's the phd d: So . professor b: This this chart this table that we 're looking at is  , show is all testing for TI - digits , or ? grad f: Bigger is worse . phd d: The upper part is for TI - digits grad f: Yeah , yeah , yeah . phd d: And the first four rows is well - matched , then the s the second group of four rows is mismatched , and finally highly mismatched . professor b: Well , What was is that i What was it that you had done last week when you showed Do you remember ? Wh - when you showed me the your table last week ? phd d: It - It was part of these results . phd a: So where is the baseline for the TI - digits located in here ? phd d: You mean the HTK Aurora baseline ? phd a: Yeah . professor b:   let 's see PLP  with on - line normalization and delta - del so that 's this thing you have circled here in the second column , phd d: Yeah . Actually I I  forgot to say that the multilingual net are trained on  features without the s derivatives  but with increased frame numbers . And we can we can see on the first line of the table that it it it 's slightly slightly worse when we don't use delta but it 's not not that much . What 's MF , MS and ME ? phd a: Multi - French , Multi - Spanish phd d: So . professor b: OK so I think what I 'm what I saw in your smaller chart that I was thinking of was was there were some numbers I saw , I think , that included these multiple languages and it and I was seeing that it got worse . In fact it might have been just this last category , having two languages broad that were where where English was removed . What I we hadn't seen yet was that if you added in the English , it 's still poor . professor b:   now , what 's the noise condition  of the training data phd d: Still poor . The noise condition is the same It 's the same  Aurora noises  , in all these cases for the training . professor b: So there 's not a statistical sta a strong st statistically different noise characteristic between  the training and test phd d: No these are the s s s same noises , professor b: and yet we 're seeing some kind of effect phd d: yeah . At least at least for the first for the well - matched , grad f: Well matched condition . professor b: So there 's some kind of a a an effect from having these  this broader coverage  Now I guess what we should try doing with this is try testing these on u this same sort of thing on you probably must have this lined up to do . So what appears is that perhaps Spanish is not very close to Italian because  , well , when using the the network trained only on Spanish it 's the error rate is almost  twice the baseline error rate . Is there any difference in So it 's in the  So you 're saying that when you train on English and  and and test on phd d: Yeah . professor b: No , you don't have training on English testing phd d: There there is another difference , is that the noise the noises are different . professor b: In in what ? phd d: Well , For for the Italian part  the  the  networks are trained with noise from Aurora TI - digits , phd e: Aurora - two . professor b: Do we have any  test sets  in any other language that  have the same noise as in the Aurora ? phd d: And phd e: Mmm , no . phd a: Can I ask something real quick ? In in the upper part in the English stuff , it looks like the very best number is sixty point nine ? and that 's in the  the third section in the upper part under PLP JRASTA , sort of the middle column ? phd d: Yeah . phd a: So that 's matched training ? Is that what that is ? phd d: It 's no , the third part , so it 's  highly mismatched . phd a: So why do you get your best number in Wouldn't you get your best number in the clean case ? phd c: Well , it 's relative to the  baseline mismatching phd d: Yeah . And then so , in the in the  in the non - mismatched clean case , your best one was under MFCC ? That sixty - one point four ? phd d: Yeah . But , what is  what is currently running , that 's  , i that just filling in the holes here or or ? pretty much ? phd d: no we don't plan to fill the holes professor b: OK . phd d: but actually there is something important , is that  we made a lot of assumption concerning the on - line normalization and we just noticed  recently that  the approach that we were using was not  leading to very good results when we used the straight features to HTK . So basically d if you look at the at the left of the table , the first  row , with eighty - six , one hundred , and forty - three and seventy - five , these are the results we obtained for Italian  with straight mmm , PLP features using on - line normalization . And the , mmm what 's in the table , just at the left of the PLP twelve on - line normalization column , so , the numbers seventy - nine , fifty - four and  forty - two are the results obtained by  Pratibha with  his on - line normalization  her on - line normalization approach . phd a: Where is that ? seventy - nine , fifty professor b: it 's just sort of sitting right on the  the column line . So these are the results of OGI with on - line normalization and straight features to HTK . And the previous result , eighty - six and so on , are with our features straight to HTK . phd d: So what we see that is there is that   the way we were doing this was not correct , but still the networks are very good . professor b: So , do you know what was wrong with the on - line normalization , or ? phd d: Yeah . There were diff there were different things and basically , the first thing is the mmm , alpha  value . I assume that this was not important because  previous results from from Dan and show that basically the both both values g give the same same  results . Actually ,  what we were doing is to start the recursion from the beginning of the utterance . phd d: And Pratibha did something different is that he  she initialed the  values of the mean and variance by computing this on the twenty - five first frames of each utterance . There were other minor differences , the fact that she used fifteen dissities instead s instead of thirteen , and that she used C - zero instead of log energy .  , I changed the code  and now we have a baseline that 's similar to the OGI baseline . phd d: We It it 's slightly  different because I don't exactly initialize the same way she does . Actually I start , mmm , I don't wait to a fifteen twenty - five twenty - five frames before computing a mean and the variance to e to to start the recursion . phd d: I I use the on - line scheme and only start the re recursion after the twenty - five twenty - fifth frame . So  I retrained the networks with these well , the the the networks are retaining with these new features . phd d: So basically what I expect is that these numbers will a little bit go down but perhaps not not so much professor b: Right . It it will learn how to normalize and professor b: OK , but I think that given the pressure of time we probably want to draw because of that especially , we wanna draw some conclusions from this , do some reductions in what we 're looking at , phd d: Yeah . professor b: and make some strong decisions for what we 're gonna do testing on before next week . So do you are you w did you have something going on , on the side , with  multi - band or on on this , phd d: Yeah I professor b: or ? phd d: No , I we plan to start this  so , act actually we have discussed  @ @  , these what we could do more as a as a research and and we were thinking perhaps that  the way we use the tandem is not  , well , there is basically perhaps a flaw in the in the the stuff because we trained the networks If we trained the networks on the on a language and a t or a specific task , professor b:   phd d: what we ask is to the network is to put the bound the decision boundaries somewhere in the space . phd d: And  mmm and ask the network to put one , at one side of the for for a particular phoneme at one side of the boundary decision boundary and one for another phoneme at the other side . And so there is kind of reduction of the information there that 's not correct because if we change task and if the phonemes are not in the same context in the new task , obviously the decision boundaries are not should not be at the same place . professor b: I di phd d: But the way the feature gives The the way the network gives the features is that it reduce completely the it removes completely the information a lot of information from the the features by   placing the decision boundaries at optimal places for one kind of data but this is not the case for another kind of data . professor b: It 's a trade - off , phd d: So professor b: right ? Any - anyway go ahead . So  what we were thinking about is perhaps  one way to solve this problem is increase the number of outputs of the neural networks .  , I I think you could make the same argument , it 'd be just as legitimate , for hybrid systems as well . phd d: Yeah but , we know that professor b: And in fact , th things get better with context dependent versions . professor b: Yeah , but it 's still true that what you 're doing is you 're ignoring you 're you 're coming up with something to represent , whether it 's a distribution , probability distribution or features , you 're coming up with a set of variables that are representing  , things that vary w over context . So , for that reason , when you in in in a hybrid system , when you incorporate context one way or another , you do get better scores . I I 'm I 'm sort of And once you the other thing is that once you represent start representing more and more context it is  much more  specific to a particular task in language . So   , the the acoustics associated with  a particular context , for instance you may have some kinds of contexts that will never occur in one language and will occur frequently in the other , so the qu the issue of getting enough training for a particular kind of context becomes harder . We already actually don't have a huge amount of training data  phd d: Yeah , but mmm , the the way we we do it now is that we have a neural network and basically the net network is trained almost to give binary decisions . professor b: It 's and and it is true that if there 's two phones that are very similar , that  the i it may prefer one but it will give a reasonably high value to the other , too . Yeah , sure but  So basically it 's almost binary decisions and  the idea of using more classes is to get something that 's less binary decisions . Because then you would say that in that this phone in this context is a one , but the same phone in a slightly different context is a zero . phd d: But yeah , but professor b: That would be even even more distinct of a binary decision . phd d: Yeah , but if professor b:  for instance , the the thing I was arguing for before , but again which I don't think we have time to try , is something in which you would modify the code so you could train to have several outputs on and use articulatory features phd d: Mmm . professor b: cuz then that would that would go that would be much broader and cover many different situations . Yeah , but I think Yeah , perhaps you 're right , but you have more classes so you you have more information in your features . phd d: because it 's it 's information that helps to discriminate , professor b:   phd d: if it 's possible to be able to discriminate among the phonemes in context . phd d: But the professor b:  we we could disagree about it at length phd d: Mmm . professor b: but the the real thing is if you 're interested in it you 'll probably try it phd d: Mmm . But but what I 'm more concerned with now , as an operational level , is  , you know , phd d: Mmm . professor b: what do we do in four or five days ?  , and so we have to be concerned with Are we gonna look at any combinations of things , you know once the nets get retrained so you have this problem out of it . professor b: are we going to look at multi - band ? Are we gonna look at combinations of things ?  , what questions are we gonna ask ,  now that , we should probably turn shortly to this O G I note .  , how are we going to combine with what they 've been focusing on ?  ,  we haven't been doing any of the L D A RASTA sort of thing . professor b: And they , although they don't talk about it in this note , there 's  , the issue of the  Mu law business  versus the logarithm , so . professor b: So what i what is going on right now ? What 's right you 've got nets retraining , Are there is there are there any H T K trainings testings going on ? phd d: N phd e: I I I 'm trying the HTK with eh , PLP twelve on - line delta - delta and MSG filter together .  professor b: And is this with the revised on - line normalization ? phd e: Ye -  , with the old older , phd d: Yeah . professor b: but again we have the hope that it We have the hope that it maybe it 's not making too much difference , phd e: Yeah . Well , something using place of articulation which which leads to nine , I think , broad classes . And then , something that combine both , and we have twenty f twenty - five ? grad f: Twenty - seven . professor b: So what you do  I just wanna understand phd d:  For the moments we do not don't have nets , professor b: so You have two net or three nets ? Was this ? How many how many nets do you have ? No nets . phd d: It 's just Were we just changing the labels to retrain nets with fewer out outputs . So you 're having multiple nets and combining them , or ?  , how are you how are you coming up with If you say  If you have a place characteristic and a manner characteristic , how do you phd d: It - It 's the single net , phd a: I think they have one output . grad f:  -  phd d: if we have twenty - seven classes , professor b: I see . professor b: So you 're sort of going the other way of what you were saying a bit ago instead of yeah . I think it will get worse because Well , I believe the effect that of of too reducing too much the information is basically basically what happens professor b:  - huh . phd d: and professor b: But you think if you include that plus the other features , phd d: but Yeah , because there is perhaps one important thing that the net brings , and OGI show showed that , is the distinction between sp speech and silence Because these nets are trained on well - controlled condition . So this is one thing And But perhaps , something intermediary using also some broad classes could could bring so much more information . professor b: And then  , just to remind me , all of that goes into  , that all of that is transformed by  , K - KL or something , or ? phd d:   phd d: or  , phd e: No transform the PLP phd d: per phd e: and only transform the other I 'm not sure . professor b: Well no , phd d: This is still something that professor b: I think I see . phd d: yeah , we don't know professor b: So there 's a question of whether you would phd e: Two e @ @ it 's one . So that 's something that you 're you haven't trained yet but are preparing to train , and phd d: Yeah . professor b: So I think , you know , we need to choose the choose the experiments carefully , so we can get  key key questions answered  before then phd d:   professor b: and leave other ones aside even if it leaves incomplete tables someplace , it 's it 's really time to time to choose .  professor b: OK , so  , Something I asked So they 're they 're doing the the VAD I guess they mean voice activity detection So again , it 's the silence So they 've just trained up a net which has two outputs , I believe .  I asked  Hynek whether I haven't talked to Sunil I asked Hynek whether they compared that to just taking the nets we already had and summing up the probabilities . To get the speech voice activity detection , or else just using the silence , if there 's only one silence output . But on the other hand , maybe they can get by with a smaller net and maybe sometimes you don't run the other , maybe there 's a computational advantage to having a separate net , anyway . professor b: there 's a an example or two that you can find , where it made it slightly worse , but  in in all but a couple examples .  how are trained the the LDA filter ? How obtained the LDA filter ? phd d: Mmm . phd e: Yeah ,  for example , LDA filter need a set of a set of training to obtain the filter . phd e: And maybe for the Italian , for the TD TE on for Finnish , these filter are are obtained with their own training set . That 's that 's so that 's a that 's a very good question , then now that it I understand it . It 's " yeah , where does the LDA come from ? " In the In earlier experiments , they had taken LDA from a completely different database , right ? phd e: Yeah . Yeah , because maybe it the same situation that the neural network training with their own phd d: Mmm .  , but  to tell you the truth , I wasn't actually looking at the LDA so much when I I was looking at it I was mostly thinking about the the VAD . And  , it ap it ap Oh what does what does ASP ? Oh that 's phd d: The features , yeah . phd e: what is what is the difference between ASP and  baseline over ? phd c: ASP . professor b: And it 's This is mostly better than baseline , although in some cases it 's a little worse , in a couple cases . professor b: I think this was I think this is the same point we were at when when we were up in Oregon . phd d: I think I think it 's the C - zero using C - zero instead of log energy . phd a: They s they say in here that the VAD is not used as an additional feature . professor b: Shouldn't it be phd d: Because phd a: Does does anybody know how they 're using it ? professor b: Yeah . professor b: if you look down at the block diagram , they estimate they get a they get an estimate of whether it 's speech or silence , phd a: But that professor b: and then they have a median filter of it . professor b: You find stretches where the combination of the frame wise VAD and the the median filter say that there 's a stretch of silence . professor b: Right ? So  phd a: So it 's it 's I don't understand . You mean it 's throwing out frames ? Before professor b: It 's throwing out chunks of frames , yeah . There 's the the median filter is enforcing that it 's not gonna be single cases of frames , or isolated frames . professor b: So it 's throwing out frames and the thing is  , what I don't understand is how they 're doing this with H T phd a: Yeah , that 's what I was just gonna ask . professor b: This is phd a: How can you just throw out frames ? professor b: Yeah . Well , you you can , phd d: i professor b: right ?  y you you phd d: Yeah . Yeah , so  in the i i in the in the decoding , you 're saying that we 're gonna decode from here to here . professor b: I think they 're they 're they 're treating it , you know , like  well , it 's not isolated word , but but connected , you know , the the phd a: In the text they say that this this is a tentative block diagram of a possible configuration we could think of . No they they have numbers though , right ? So I think they 're they 're doing something like that . I think that they 're they 're I think what  by tha that is they 're trying to come up with a block diagram that 's plausible for the standard . In other words , it 's   from the point of view of of  reducing the number of bits you have to transmit it 's not a bad idea to detect silence anyway . I 'm just wondering what exactly did they do up in this table if it wasn't this . But it 's the thing is it 's that that that 's that 's I I Certainly it would be tricky about it intrans in transmitting voice ,   for listening to , is that these kinds of things  cut speech off a lot . professor b: It does introduce delays but they 're claiming that it 's it 's within the the boundaries of it . professor b: And the LDA introduces delays , and b what he 's suggesting this here is a parallel path so that it doesn't introduce  , any more delay . I it introduces two hundred milliseconds of delay but at the same time the LDA down here I don't know Wh what 's the difference between TLDA and SLDA ? phd c: Temporal and spectral . The temporal LDA does in fact include the same so that I think he well , by by saying this is a b a tentative block di diagram I think means if you construct it this way , this this delay would work in that way phd a: Ah . So  I think that it 's it 's nice to do that in this because in fact , it 's gonna give a better word error result and therefore will help within an evaluation .  , as you know , part of the problem with evaluation right now is that the word models are pretty bad and nobody wants has has approached improving them . So it 's possible that a lot of the problems with so many insertions and so forth would go away if they were better word models to begin with . So  The question we 're gonna wanna go through next week when Hynek shows up I guess is given that we 've been if you look at what we 've been trying , we 're  looking at  , by then I guess , combinations of features and multi - band  , and we 've been looking at cross - language , cross task issues . And I guess when he comes here we 're gonna have to start deciding about  what do we choose from what we 've looked at to  blend with some group of things in what they 've looked at And once we choose that , how do we split up the effort ?  , because we still have even once we choose , we 've still got  another month or so ,  there 's holidays in the way , but but  I think the evaluation data comes January thirty - first so there 's still a fair amount of time to do things together it 's just that they probably should be somewhat more coherent between the two sites in that that amount of time . phd a: When they removed the silence frames , did they insert some kind of a marker so that the recognizer knows it 's knows when it 's time to back trace or something ? professor b: Well , see they , I I think they 're  . They 're they 're getting around the way the recognizer works because they 're not allowed to  , change the scripts for the recognizer , I believe . professor b:  that 's sort of what the way I had imagined would happen is that on the other side , yeah you p put some low level noise or something . professor b: Most recognizers don't like zeros but but you know , put some epsilon in or some rand phd a: Yeah .  i w Or something professor b: Maybe not a constant but it doesn't ,  don't like to divide by the variance of that , but  it 's phd a: That 's right . or else ,   maybe there is some indicator to tell it to start and stop , I don't know . Otherwise , if it 's just a bunch of speech , stuck together professor b: No they 're phd a: Yeah . And   I think  , I wanna look at these numbers off - line a little bit and think about it and and talk with everybody  , outside of this meeting .  , but  No  it sounds like  there there there are the usual number of of little little problems and bugs and so forth but it sounds like they 're getting ironed out . And now we 're seem to be kind of in a position to actually  , look at stuff and and and compare things .  I don't know what the One of the things I wonder about , coming back to the first results you talked about , is is how much ,  things could be helped by more parameters . Because anyway when we go to twice as much data and have the same number of parameters , particularly when it 's twice as much data and it 's quite diverse , I wonder if having twice as many parameters would help . How are we doing on the resources ? Disk , and phd d: I think we 're alright , professor b: OK . professor b: Are were you folks using Gin ? That 's a that just died , you know ? phd d: Mmm , no . professor b: That 'll be It 's a seven hundred fifty megahertz  SUN phd d:  . grad g: Do we Do we have that big new IBM machine the , I think in th professor b: We have the little tiny IBM machine that might someday grow up to be a big IBM machine . It 's got s slots for eight ,  IBM was donating five , I think we only got two so far , processors . So instead of having eight processors that were eight hundred megahertz , we ended up with two that are five hundred and fifty megahertz . So I don't think anybody has been sufficiently excited by it to spend much time  with it , but  Hopefully , they 'll get us some more parts , soon and  , yeah , I think that 'll be once we get it populated , that 'll be a nice machine . grad g: And if we can do things on Linux , some of the machines we have going already , like Swede ? professor b:   And it does have two processors , you know and Somebody could do you know , check out  the multi - threading libraries . And  i it 's possible that the  , I guess the prudent thing to do would be for somebody to do the work on on getting our code running on that machine with two processors even though there aren't five or eight . There 's there 's there 's gonna be debugging hassles and then we 'd be set for when we did have five or eight , to have it really be useful . You don't get the don't get the visuals but grad g: I is it  mostly  the neural network trainings that are  slowing us down or the HTK runs that are slowing us down ? professor b: I think yes .  , Isn't that right ?  I think you 're you 're sort of held up by both , right ? If the if the neural net trainings were a hundred times faster you still wouldn't be anything running through these a hundred times faster because you 'd be stuck by the HTK trainings , phd d: Mmm . professor b: But if the HTK  I think they 're both It sounded like they were roughly equal ? Is that about right ? phd d: Yeah . grad g: Because ,  I think that 'll be running Linux , and Sw - Swede and Fudge are already running Linux so ,  I could try to get  the train the neural network trainings or the HTK stuff running under Linux , and to start with I 'm wondering which one I should pick first . professor b: probably the neural net cuz it 's probably it it 's it 's  Well , I I don't know . They both HTK we use for  this Aurora stuff   , I think It 's not clear yet what we 're gonna use for trainings  Well , there 's the trainings  is it the training that takes the time , or the decoding ?  , is it about equal between the two ? For for Aurora ? phd d: For HTK ? professor b: For Yeah . Well , I don't know how we can I don't know how to Do we have HTK source ? Is that Yeah . professor b: You would think that would fairly trivially the training would , anyway , th the testing  I don't I don't think would parallelize all that well . But I think that you could certainly do d  , distributed , sort of Ah , no , it 's the each individual sentence is pretty tricky to parallelize . phd a: They have a they have a thing for doing that and th they have for awhile , in H T And you can parallelize the training . professor b: Yeah ? phd a: And run it on several machines professor b: Aha ! phd a: and it just basically keeps counts . phd a: I don't what their scripts are set up to do for the Aurora stuff , but phd d: Yeah . professor b: Something that we haven't really settled on yet is other than this Aurora stuff ,  what do we do , large vocabulary training slash testing for  tandem systems . So I I think the the advantage of going with the neural net thing is that we 're gonna use the neural net trainings , no matter what , for a lot of the things we 're doing , grad g: OK . professor b: whereas , w exactly which  Gaussian - mixture - based  thing we use is gonna depend  So with that , maybe we should  go to our digit recitation task . I think we can @ @ You know Herve 's coming tomorrow , right ? Herve will be giving a talk , yeah , talk at eleven . Did  , did everybody sign these consent Er everybody Has everyone signed a consent form before , on previous meetings ? You don't have to do it again each time Yes 